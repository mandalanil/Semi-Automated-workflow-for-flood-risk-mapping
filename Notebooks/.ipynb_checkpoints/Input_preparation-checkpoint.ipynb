{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "subsets rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from arcpy.sa import *\n",
    "arcpy.env.addOutputsToMap = False\n",
    "# Enable overwriting of output files\n",
    "arcpy.env.overwriteOutput = True\n",
    "# Check out the Spatial Analyst extension\n",
    "arcpy.CheckOutExtension(\"Spatial\")\n",
    "# Define the directory where you want to start searching for .shp files\n",
    "start_directory = r'T:\\amandal2023$\\Working'\n",
    "\n",
    "hucname=\"NAME\"\n",
    "DEMft=r'T:\\amandal2023$\\dem_5ft\\sfmosaic_ft.tif'\n",
    "WTEft=r'T:\\aurusan$\\THindle\\GW_Surfaces\\WTEft_PBC_BRW.tif'\n",
    "WHC=r'Y:\\Datasets\\FL_Soil\\aws0_150_whc1.tif'\n",
    "ImperviousBinary=r'Y:\\Datasets\\Impervious\\ImperviousBinary\\Binary_Impervious_OK.dat'\n",
    "WaterBinary=r'Y:\\Datasets\\FL_Waterbodies\\Water_Raster\\Binary_Water.tif'\n",
    "FlowLine=r'T:\\amandal2023$\\Miami-Dade\\Data\\Drainage_Lines.shp'\n",
    "SurfaceStations=r'T:\\amandal2023$\\Miami-Dade\\Data\\Miami_Stations.shp'\n",
    "r1d5yr=r'Y:\\Datasets\\FL_NOAA14_Precipitation\\se5y1d_inch.tif'\n",
    "r1d10yr=r'Y:\\Datasets\\FL_NOAA14_Precipitation\\se10yr1d_inch.tif'\n",
    "r1d100yr=r'Y:\\Datasets\\FL_NOAA14_Precipitation\\se100yr24h_inch.tif'\n",
    "r3d25yr=r'Y:\\Datasets\\FL_NOAA14_Precipitation\\se25y3d_inch.tif'\n",
    "\n",
    "dlist={'DEMft':DEMft,'WTEft':WTEft,'WHC':WHC,'ImperviousBinary':ImperviousBinary,\n",
    "       'WaterBinary':WaterBinary,'r1d5yr':r1d5yr,'r1d10yr':r1d10yr,'r1d100yr':r1d100yr,'r3d25yr':r3d25yr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEMft\n",
      "T:\\amandal2023$\\Working\\Hialeah\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\DEMft\\SNAKE_CREEK_CANAL_DEMft.tif\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\DEMft\\LITTLE_RIVER_CANAL_DEMft.tif\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\DEMft\\BISCAYNE_CANAL_DEMft.tif\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\DEMft\\MIAMI_RIVER_DEMft.tif\n",
      "DEMft\n",
      "T:\\amandal2023$\\Working\\Hialeah\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\DEMft\\HIALEAH_HUC12s_DEMft.tif\n",
      "DEMft\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\DEMft\\NORTH_MIAMI_HUC12s_DEMft.tif\n",
      "DEMft\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\DEMft\\NORTH_BISCAYNE_BAY_DEMft.tif\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\DEMft\\LITTLE_RIVER_CANAL_DEMft.tif\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\DEMft\\BISCAYNE_CANAL_DEMft.tif\n",
      "WTEft\n",
      "T:\\amandal2023$\\Working\\Hialeah\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\WTEft\\SNAKE_CREEK_CANAL_WTEft.tif\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\WTEft\\LITTLE_RIVER_CANAL_WTEft.tif\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\WTEft\\BISCAYNE_CANAL_WTEft.tif\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\WTEft\\MIAMI_RIVER_WTEft.tif\n",
      "WTEft\n",
      "T:\\amandal2023$\\Working\\Hialeah\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\WTEft\\HIALEAH_HUC12s_WTEft.tif\n",
      "WTEft\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\WTEft\\NORTH_MIAMI_HUC12s_WTEft.tif\n",
      "WTEft\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\WTEft\\NORTH_BISCAYNE_BAY_WTEft.tif\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\WTEft\\LITTLE_RIVER_CANAL_WTEft.tif\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\WTEft\\BISCAYNE_CANAL_WTEft.tif\n",
      "WHC\n",
      "T:\\amandal2023$\\Working\\Hialeah\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\WHC\\SNAKE_CREEK_CANAL_WHC.tif\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\WHC\\LITTLE_RIVER_CANAL_WHC.tif\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\WHC\\BISCAYNE_CANAL_WHC.tif\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\WHC\\MIAMI_RIVER_WHC.tif\n",
      "WHC\n",
      "T:\\amandal2023$\\Working\\Hialeah\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\WHC\\HIALEAH_HUC12s_WHC.tif\n",
      "WHC\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\WHC\\NORTH_MIAMI_HUC12s_WHC.tif\n",
      "WHC\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\WHC\\NORTH_BISCAYNE_BAY_WHC.tif\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\WHC\\LITTLE_RIVER_CANAL_WHC.tif\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\WHC\\BISCAYNE_CANAL_WHC.tif\n",
      "ImperviousBinary\n",
      "T:\\amandal2023$\\Working\\Hialeah\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\ImperviousBinary\\SNAKE_CREEK_CANAL_ImperviousBinary.tif\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\ImperviousBinary\\LITTLE_RIVER_CANAL_ImperviousBinary.tif\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\ImperviousBinary\\BISCAYNE_CANAL_ImperviousBinary.tif\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\ImperviousBinary\\MIAMI_RIVER_ImperviousBinary.tif\n",
      "ImperviousBinary\n",
      "T:\\amandal2023$\\Working\\Hialeah\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\ImperviousBinary\\HIALEAH_HUC12s_ImperviousBinary.tif\n",
      "ImperviousBinary\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\ImperviousBinary\\NORTH_MIAMI_HUC12s_ImperviousBinary.tif\n",
      "ImperviousBinary\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\ImperviousBinary\\NORTH_BISCAYNE_BAY_ImperviousBinary.tif\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\ImperviousBinary\\LITTLE_RIVER_CANAL_ImperviousBinary.tif\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\ImperviousBinary\\BISCAYNE_CANAL_ImperviousBinary.tif\n",
      "WaterBinary\n",
      "T:\\amandal2023$\\Working\\Hialeah\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\WaterBinary\\SNAKE_CREEK_CANAL_WaterBinary.tif\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\WaterBinary\\LITTLE_RIVER_CANAL_WaterBinary.tif\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\WaterBinary\\BISCAYNE_CANAL_WaterBinary.tif\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\WaterBinary\\MIAMI_RIVER_WaterBinary.tif\n",
      "WaterBinary\n",
      "T:\\amandal2023$\\Working\\Hialeah\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\WaterBinary\\HIALEAH_HUC12s_WaterBinary.tif\n",
      "WaterBinary\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\WaterBinary\\NORTH_MIAMI_HUC12s_WaterBinary.tif\n",
      "WaterBinary\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\WaterBinary\\NORTH_BISCAYNE_BAY_WaterBinary.tif\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\WaterBinary\\LITTLE_RIVER_CANAL_WaterBinary.tif\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\WaterBinary\\BISCAYNE_CANAL_WaterBinary.tif\n",
      "r1d5yr\n",
      "T:\\amandal2023$\\Working\\Hialeah\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\r1d5yr\\SNAKE_CREEK_CANAL_r1d5yr.tif\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\r1d5yr\\LITTLE_RIVER_CANAL_r1d5yr.tif\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\r1d5yr\\BISCAYNE_CANAL_r1d5yr.tif\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\r1d5yr\\MIAMI_RIVER_r1d5yr.tif\n",
      "r1d5yr\n",
      "T:\\amandal2023$\\Working\\Hialeah\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\r1d5yr\\HIALEAH_HUC12s_r1d5yr.tif\n",
      "r1d5yr\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\r1d5yr\\NORTH_MIAMI_HUC12s_r1d5yr.tif\n",
      "r1d5yr\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\r1d5yr\\NORTH_BISCAYNE_BAY_r1d5yr.tif\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\r1d5yr\\LITTLE_RIVER_CANAL_r1d5yr.tif\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\r1d5yr\\BISCAYNE_CANAL_r1d5yr.tif\n",
      "r1d10yr\n",
      "T:\\amandal2023$\\Working\\Hialeah\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\r1d10yr\\SNAKE_CREEK_CANAL_r1d10yr.tif\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\r1d10yr\\LITTLE_RIVER_CANAL_r1d10yr.tif\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\r1d10yr\\BISCAYNE_CANAL_r1d10yr.tif\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\r1d10yr\\MIAMI_RIVER_r1d10yr.tif\n",
      "r1d10yr\n",
      "T:\\amandal2023$\\Working\\Hialeah\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\r1d10yr\\HIALEAH_HUC12s_r1d10yr.tif\n",
      "r1d10yr\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\r1d10yr\\NORTH_MIAMI_HUC12s_r1d10yr.tif\n",
      "r1d10yr\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\r1d10yr\\NORTH_BISCAYNE_BAY_r1d10yr.tif\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\r1d10yr\\LITTLE_RIVER_CANAL_r1d10yr.tif\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\r1d10yr\\BISCAYNE_CANAL_r1d10yr.tif\n",
      "r1d100yr\n",
      "T:\\amandal2023$\\Working\\Hialeah\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\r1d100yr\\SNAKE_CREEK_CANAL_r1d100yr.tif\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\r1d100yr\\LITTLE_RIVER_CANAL_r1d100yr.tif\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\r1d100yr\\BISCAYNE_CANAL_r1d100yr.tif\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\r1d100yr\\MIAMI_RIVER_r1d100yr.tif\n",
      "r1d100yr\n",
      "T:\\amandal2023$\\Working\\Hialeah\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\r1d100yr\\HIALEAH_HUC12s_r1d100yr.tif\n",
      "r1d100yr\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\r1d100yr\\NORTH_MIAMI_HUC12s_r1d100yr.tif\n",
      "r1d100yr\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\r1d100yr\\NORTH_BISCAYNE_BAY_r1d100yr.tif\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\r1d100yr\\LITTLE_RIVER_CANAL_r1d100yr.tif\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\r1d100yr\\BISCAYNE_CANAL_r1d100yr.tif\n",
      "r3d25yr\n",
      "T:\\amandal2023$\\Working\\Hialeah\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\r3d25yr\\SNAKE_CREEK_CANAL_r3d25yr.tif\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\r3d25yr\\LITTLE_RIVER_CANAL_r3d25yr.tif\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\r3d25yr\\BISCAYNE_CANAL_r3d25yr.tif\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\r3d25yr\\MIAMI_RIVER_r3d25yr.tif\n",
      "r3d25yr\n",
      "T:\\amandal2023$\\Working\\Hialeah\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\r3d25yr\\HIALEAH_HUC12s_r3d25yr.tif\n",
      "r3d25yr\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\r3d25yr\\NORTH_MIAMI_HUC12s_r3d25yr.tif\n",
      "r3d25yr\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\r3d25yr\\NORTH_BISCAYNE_BAY_r3d25yr.tif\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\r3d25yr\\LITTLE_RIVER_CANAL_r3d25yr.tif\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\r3d25yr\\BISCAYNE_CANAL_r3d25yr.tif\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from arcpy.sa import *\n",
    "arcpy.env.addOutputsToMap = False\n",
    "# Enable overwriting of output files\n",
    "arcpy.env.overwriteOutput = True\n",
    "# Check out the Spatial Analyst extension\n",
    "arcpy.CheckOutExtension(\"Spatial\")\n",
    "# Define the directory where you want to start searching for .shp files\n",
    "start_directory = r'T:\\amandal2023$\\Working'\n",
    "hucname=\"NAME\"\n",
    "# Use the glob library to search for .shp files in subdirectories\n",
    "shp_files = glob.glob(os.path.join(start_directory, '**/StatePlane/*.shp'), recursive=True)\n",
    "for dirs, data in dlist.items():\n",
    "    \n",
    "    # Print the list of .shp files\n",
    "    for shp_file in shp_files:\n",
    "        #print(shp_file)\n",
    "        print(dirs)\n",
    "        # Split the file path into directory and file name\n",
    "        directory, file_name = os.path.split(shp_file)\n",
    "        print(directory)\n",
    "        output_folder=directory.replace('Huc12\\StatePlane','HucWise'+'\\\\'+dirs)\n",
    "        # Make sure the output folder exists, or create it if it doesn't\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "        # Create a cursor to iterate through the rows of the shapefile\n",
    "        with arcpy.da.SearchCursor(shp_file, [\"SHAPE@\", hucname]) as cursor:\n",
    "            for row in cursor:\n",
    "                # Define the output raster name based on the OID or any unique identifier\n",
    "                clipped = str(row[1].replace(' ','_'))+f'_{dirs}.tif'\n",
    "                cliped_wte=os.path.join(output_folder, clipped)\n",
    "                print(cliped_wte)\n",
    "\n",
    "                # Clip the raster using the polygon geometry in the current row\n",
    "                arcpy.Clip_management(\n",
    "                    in_raster=data,\n",
    "                    out_raster=cliped_wte,\n",
    "                    in_template_dataset=row[0],\n",
    "                    clipping_geometry=\"ClippingGeometry\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate SoilStorage and Unsaturated Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hialeah\n",
      "BISCAYNE_CANAL_DEMft.tif\n",
      "Hialeah_city_DEMft.tif\n",
      "LITTLE_RIVER_CANAL_DEMft.tif\n",
      "MIAMI_RIVER_DEMft.tif\n",
      "SNAKE_CREEK_CANAL_DEMft.tif\n",
      "_DEMft.tif\n",
      "NorthMiami\n",
      "BISCAYNE_CANAL_DEMft.tif\n",
      "LITTLE_RIVER_CANAL_DEMft.tif\n",
      "NORTH_BISCAYNE_BAY_DEMft.tif\n",
      "North_Miami_city_DEMft.tif\n",
      "_DEMft.tif\n"
     ]
    }
   ],
   "source": [
    "def outfolder(output_folder):\n",
    "    # Make sure the output folder exists, or create it if it doesn't\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "for folder in['Hialeah','NorthMiami']:\n",
    "    # Use the glob library to search for .tif files in subdirectories named \"DEM\"\n",
    "    dem_files = glob.glob(os.path.join(start_directory, f'{folder}\\HucWise\\DEMft\\*.tif'), recursive=True)\n",
    "    print(folder)\n",
    "    for dem_file in dem_files:\n",
    "        dirs, filename = os.path.split(dem_file)\n",
    "        print(filename)\n",
    "        WTEft=dem_file.replace('DEMft','WTEft')\n",
    "        WHC=dem_file.replace('DEMft','WHC')\n",
    "        ImperviousBinary=dem_file.replace('DEMft','ImperviousBinary')\n",
    "        WaterBinary=dem_file.replace('DEMft','WaterBinary')\n",
    "        soilstorage_folder=outfolder(dirs.replace('DEMft','soilStorage'))\n",
    "        unsaturated_folder=outfolder(dirs.replace('DEMft','unsaturated'))\n",
    "        soilstorage=dem_file.replace('DEMft','soilStorage')\n",
    "        unsaturated=dem_file.replace('DEMft','unsaturated')\n",
    "        soil_outras=RasterCalculator([dem_file,WTEft,WHC,ImperviousBinary,WaterBinary,12],\n",
    "                                    [\"a\", \"b\",\"d\",\"e\",\"f\",\"g\"], \n",
    "                                    \"float((a-b)*d*e*f*g)\")\n",
    "        soil_outras.save(soilstorage)\n",
    "        outdata=Con(soilstorage, soilstorage, 0, \"VALUE >0\")\n",
    "        outdata.save(soilstorage)\n",
    "        un_outras=RasterCalculator([dem_file,WTEft],[\"a\", \"b\"], \"float(a-b)\")\n",
    "        un_outras.save(unsaturated)\n",
    "        outdata=Con(unsaturated, unsaturated, 0, \"VALUE >0\")\n",
    "        outdata.save(unsaturated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Inputs for Cascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hialeah\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1]:55: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "[1]:55: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "[1]:55: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "[1]:55: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "[1]:55: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NorthMiami\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1]:55: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "[1]:55: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "[1]:55: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "[1]:55: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from arcpy.sa import *\n",
    "arcpy.env.addOutputsToMap = False\n",
    "# Check out the ArcGIS Spatial Analyst extension license\n",
    "arcpy.CheckOutExtension(\"Spatial\")\n",
    "# Enable overwriting of output files\n",
    "arcpy.env.overwriteOutput = True\n",
    "# Define the directory where you want to start searching for .shp files\n",
    "start_directory = r'T:\\amandal2023$\\Working'\n",
    "\n",
    "def stat(ras):\n",
    "    minv = arcpy.GetRasterProperties_management(ras, \"MINIMUM\")\n",
    "    maxv = arcpy.GetRasterProperties_management(ras, \"MAXIMUM\")\n",
    "    meanv = arcpy.GetRasterProperties_management(ras, \"MEAN\")\n",
    "    return[minv,maxv,meanv]\n",
    "\n",
    "    \n",
    "for folder in['Hialeah','NorthMiami']:\n",
    "    df=pd.DataFrame()\n",
    "    # Use the glob library to search for .tif files in subdirectories named \"DEM\"\n",
    "    dem_files = glob.glob(os.path.join(start_directory, f'{folder}\\HucWise\\DEMft\\*.tif'), recursive=True)\n",
    "    cascadeinputs=os.path.join(start_directory, f'{folder}\\Cascade.xlsx')\n",
    "    print(folder)\n",
    "    for dem_file in dem_files:\n",
    "        dirs, filename = os.path.split(dem_file)\n",
    "        HUC=(filename.replace('.tif','')).replace('_',' ')\n",
    "        # For example, setting all cells with a specific value (e.g., 0) to NoData\n",
    "        #condition = Raster(dem_file) <0\n",
    "        # Use the SetNull function to set NoData for the specified condition\n",
    "        #output_ras = SetNull(condition, dem_file)\n",
    "        dem=stat(dem_file)\n",
    "        WTEft=dem_file.replace('DEMft','WTEft')\n",
    "        WHC=dem_file.replace('DEMft','WHC')\n",
    "        ImperviousBinary=dem_file.replace('DEMft','ImperviousBinary')\n",
    "        WaterBinary=dem_file.replace('DEMft','WaterBinary')\n",
    "        r1d5yr=stat(dem_file.replace('DEMft','r1d5yr'))[2]\n",
    "        r1d10yr=stat(dem_file.replace('DEMft','r1d10yr'))[2]\n",
    "        r1d100yr=stat(dem_file.replace('DEMft','r1d100yr'))[2]\n",
    "        r3d25yr=stat(dem_file.replace('DEMft','r3d25yr'))[2]\n",
    "        scclist=[]\n",
    "        for i in range(0,6):\n",
    "            output_raster=os.path.join(r'T:\\amandal2023$\\Temp\\scc',filename.replace('.tif',f'{i}.tif'))\n",
    "            outras=RasterCalculator([dem_file,WTEft, i,WHC,ImperviousBinary,WaterBinary,12],\n",
    "                                    [\"a\", \"b\",\"c\",\"d\",\"e\",\"f\",\"g\"], \n",
    "                                    \"float((a-(b+c))*d*e*f*g)\")\n",
    "            outras.save(output_raster)\n",
    "            outdata=Con(output_raster, output_raster, 0, \"VALUE >0\")\n",
    "            outdata.save(output_raster)\n",
    "            scc=stat(output_raster)[2]\n",
    "            scclist.append(scc)\n",
    "        \n",
    "        # Append the row to the DataFrame\n",
    "        df = df.append({'HUC':HUC,'MaxElevation':dem[1],'MinElevation':dem[0],'r1d5yr':r1d5yr,\n",
    "                       'r1d10yr':r1d10yr,'r1d100yr':r1d100yr,'r3d25yr':r3d25yr,\n",
    "                        'SCC0ft':scclist[0], 'SCC1ft':scclist[1],\n",
    "                        'SCC2ft':scclist[2],'SCC3ft':scclist[3],'SCC4ft':scclist[4],'SCC5ft':scclist[5]}, ignore_index=True)\n",
    "    df.to_excel(cascadeinputs)\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "clip vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T:\\amandal2023$\\Miami-Dade\\Data\\Drainage_Lines.shp\n",
      "T:\\amandal2023$\\Working\\Hialeah\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\Hialeah\\Vector\\SNAKE_CREEK_CANAL_Fl.shp\n",
      "T:\\amandal2023$\\Working\\Hialeah\\Vector\\LITTLE_RIVER_CANAL_Fl.shp\n",
      "T:\\amandal2023$\\Working\\Hialeah\\Vector\\BISCAYNE_CANAL_Fl.shp\n",
      "T:\\amandal2023$\\Working\\Hialeah\\Vector\\MIAMI_RIVER_Fl.shp\n",
      "T:\\amandal2023$\\Miami-Dade\\Data\\Drainage_Lines.shp\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\Vector\\NORTH_BISCAYNE_BAY_Fl.shp\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\Vector\\LITTLE_RIVER_CANAL_Fl.shp\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\Vector\\BISCAYNE_CANAL_Fl.shp\n",
      "T:\\amandal2023$\\Miami-Dade\\Data\\Miami_Stations.shp\n",
      "T:\\amandal2023$\\Working\\Hialeah\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\Hialeah\\Vector\\SNAKE_CREEK_CANAL_Sp.shp\n",
      "T:\\amandal2023$\\Working\\Hialeah\\Vector\\LITTLE_RIVER_CANAL_Sp.shp\n",
      "T:\\amandal2023$\\Working\\Hialeah\\Vector\\BISCAYNE_CANAL_Sp.shp\n",
      "T:\\amandal2023$\\Working\\Hialeah\\Vector\\MIAMI_RIVER_Sp.shp\n",
      "T:\\amandal2023$\\Miami-Dade\\Data\\Miami_Stations.shp\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\Vector\\NORTH_BISCAYNE_BAY_Sp.shp\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\Vector\\LITTLE_RIVER_CANAL_Sp.shp\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\Vector\\BISCAYNE_CANAL_Sp.shp\n"
     ]
    }
   ],
   "source": [
    "dlist={FlowLine:'Fl',SurfaceStations:'Sp'}\n",
    "import os\n",
    "import glob\n",
    "from arcpy.sa import *\n",
    "arcpy.env.addOutputsToMap = False\n",
    "# Enable overwriting of output files\n",
    "arcpy.env.overwriteOutput = True\n",
    "# Check out the Spatial Analyst extension\n",
    "arcpy.CheckOutExtension(\"Spatial\")\n",
    "# Define the directory where you want to start searching for .shp files\n",
    "start_directory = r'T:\\amandal2023$\\Working'\n",
    "hucname=\"NAME\"\n",
    "# Use the glob library to search for .shp files in subdirectories\n",
    "shp_files = glob.glob(os.path.join(start_directory, '**/StatePlane/*.shp'), recursive=True)\n",
    "for dirs, data in dlist.items():\n",
    "    \n",
    "    # Print the list of .shp files\n",
    "    for shp_file in shp_files:\n",
    "        #print(shp_file)\n",
    "        print(dirs)\n",
    "        # Split the file path into directory and file name\n",
    "        directory, file_name = os.path.split(shp_file)\n",
    "        print(directory)\n",
    "        output_folder=directory.replace('Huc12\\StatePlane','Vector')\n",
    "        # Make sure the output folder exists, or create it if it doesn't\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "        # Create a cursor to iterate through the rows of the shapefile\n",
    "        with arcpy.da.SearchCursor(shp_file, [\"SHAPE@\", hucname]) as cursor:\n",
    "            for row in cursor:\n",
    "                # Define the output raster name based on the OID or any unique identifier\n",
    "                clipped = str(row[1].replace(' ','_'))+f'_{data}.shp'\n",
    "                cliped_wte=os.path.join(output_folder, clipped)\n",
    "                print(cliped_wte)\n",
    "                # Perform the clip operation\n",
    "                arcpy.analysis.Clip(dirs, row[0], cliped_wte)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def mkfolder(output_folder):\n",
    "    # Make sure the output folder exists, or create it if it doesn't\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    return output_folder\n",
    "def clipras()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clipped raster saved as T:\\Working\\Hialeah\\DEM\\SNAKE_CREEK_CANAL_ft.tif\n",
      "Clipped raster saved as T:\\Working\\Hialeah\\DEM\\LITTLE_RIVER_CANAL_ft.tif\n",
      "Clipped raster saved as T:\\Working\\Hialeah\\DEM\\BISCAYNE_CANAL_ft.tif\n",
      "Clipped raster saved as T:\\Working\\Hialeah\\DEM\\MIAMI_RIVER_ft.tif\n",
      "Clipped raster saved as T:\\Working\\NorthMiami\\DEM\\NORTH_BISCAYNE_BAY_ft.tif\n",
      "Clipped raster saved as T:\\Working\\NorthMiami\\DEM\\LITTLE_RIVER_CANAL_ft.tif\n",
      "Clipped raster saved as T:\\Working\\NorthMiami\\DEM\\BISCAYNE_CANAL_ft.tif\n",
      "Dem process completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from arcpy.sa import *\n",
    "arcpy.env.addOutputsToMap = False\n",
    "# Enable overwriting of output files\n",
    "arcpy.env.overwriteOutput = True\n",
    "# Check out the Spatial Analyst extension\n",
    "arcpy.CheckOutExtension(\"Spatial\")\n",
    "# Define the directory where you want to start searching for .shp files\n",
    "start_directory = r'T:\\amandal2023$\\Working'\n",
    "DEM_folder='DEM'\n",
    "WTE_folder=\n",
    "hucname=\"NAME\"\n",
    "DEM=r'Y:\\Datasets\\LiDAR_DEM\\DEM_3m_merged\\MERGED\\sfmosaic.tif'\n",
    "\n",
    "# Use the glob library to search for .shp files in subdirectories\n",
    "shp_files = glob.glob(os.path.join(start_directory, '**/StatePlane/*.shp'), recursive=True)\n",
    "\n",
    "# Print the list of .shp files\n",
    "for shp_file in shp_files:\n",
    "    # Split the file path into directory and file name\n",
    "    directory, file_name = os.path.split(shp_file)\n",
    "    output_folder=directory.replace('Huc12/StatePlane',folder)\n",
    "    # Make sure the output folder exists, or create it if it doesn't\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    # Create a cursor to iterate through the rows of the shapefile\n",
    "    with arcpy.da.SearchCursor(shp_file, [\"SHAPE@\", hucname]) as cursor:\n",
    "        for row in cursor:\n",
    "            # Define the output raster name based on the OID or any unique identifier\n",
    "            clipped = str(row[1].replace(' ','_'))+'tmp.tif'\n",
    "            cliped_dem=os.path.join(output_folder, clipped)\n",
    "\n",
    "            # Clip the raster using the polygon geometry in the current row\n",
    "            arcpy.Clip_management(\n",
    "                in_raster=raster_to_clip,\n",
    "                out_raster=cliped_dem,\n",
    "                in_template_dataset=row[0],\n",
    "                clipping_geometry=\"ClippingGeometry\"\n",
    "            )\n",
    "            output_filled_dem=cliped_dem.replace('tmp.tif','fill.tif')\n",
    "            # Use the Fill tool to fill sinks in the DEM\n",
    "            arcpy.gp.Fill_sa(cliped_dem, output_filled_dem)\n",
    "            dem_ft=cliped_dem.replace('tmp.tif','_ft.tif')\n",
    "            \n",
    "            # Multiply the raster by 3.28084 to convert meters to feet\n",
    "            output = RasterCalculator([output_filled_dem, 3.28084],[\"x\", \"y\"], \"float(x*y)\")\n",
    "\n",
    "            # Save the result to an output raster\n",
    "            output.save(dem_ft)\n",
    "            arcpy.Delete_management(cliped_dem)\n",
    "            arcpy.Delete_management(output_filled_dem)\n",
    "            \n",
    "\n",
    "            print(f\"Clipped raster saved as {dem_ft}\")\n",
    "\n",
    "print(\"Dem process completed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Stream Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed T:\\amandal2023$\\Working\\Hialeah\\DEM\\BISCAYNE_CANAL_ft.tif\n",
      "processed T:\\amandal2023$\\Working\\Hialeah\\DEM\\LITTLE_RIVER_CANAL_ft.tif\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from arcpy.sa import *\n",
    "arcpy.env.addOutputsToMap = False\n",
    "# Enable overwriting of output files\n",
    "arcpy.env.overwriteOutput = True\n",
    "# Check out the Spatial Analyst extension\n",
    "arcpy.CheckOutExtension(\"Spatial\")\n",
    "# Define the directory where you want to start searching for .shp files\n",
    "start_directory = r'T:\\amandal2023$\\Working'\n",
    "outras='Hydro2'\n",
    "outvector='Drainage2'\n",
    "# Use the glob library to search for .tif files in subdirectories named \"DEM\"\n",
    "dem_files = glob.glob(os.path.join(start_directory, '**/DEM/*.tif'), recursive=True)\n",
    "def mfolder(path):\n",
    "    # Make sure the output folder exists, or create it if it doesn't\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    return(path)\n",
    "    \n",
    "# Print the list of .tif files\n",
    "for dem_file in dem_files:\n",
    "    # Split the file path into directory and file name\n",
    "    directory, file_name = os.path.split(dem_file)\n",
    "    output_raster=mfolder(directory.replace('DEM',outras))\n",
    "    output_vector=mfolder(directory.replace('DEM',outvector))\n",
    "\n",
    "    # Step 1: Calculate Flow Direction\n",
    "    flow_direction = FlowDirection(dem_file, \"NORMAL\")\n",
    "\n",
    "    # Step 2: Calculate Flow Accumulation\n",
    "    flow_accumulation = FlowAccumulation(flow_direction)\n",
    "\n",
    "    # Step 3: Define Streams (Optional)\n",
    "    # Adjust the threshold value as needed to define streams\n",
    "    stream_definition = Con(flow_accumulation > 8000, 5)\n",
    "\n",
    "    # Step 4: Stream Segmentation\n",
    "    stream_link = StreamLink(flow_direction, stream_definition)\n",
    "    stream_order = StreamOrder(stream_link, flow_direction)\n",
    "\n",
    "    # Step 5: Create Catchment Grid\n",
    "    catchment_grid = Watershed(flow_direction, stream_link)\n",
    "\n",
    "    # Step 6: Create Catchment Polygon\n",
    "    catchment_polygon = arcpy.RasterToPolygon_conversion(catchment_grid, \"in_memory/catchment_polygons\", \"NO_SIMPLIFY\")\n",
    "\n",
    "    # Step 7: Create Drainage Line\n",
    "    drainage_line = StreamToFeature(stream_link, flow_direction, \"in_memory/drainage_lines\")\n",
    "\n",
    "    # Step 8: Create Drainage Point\n",
    "    drainage_point = arcpy.RasterToPoint_conversion(stream_link, \"in_memory/drainage_points\")\n",
    "\n",
    "    # Save the results\n",
    "\n",
    "    flow_direction.save(os.path.join(output_raster, file_name.replace('_ft.tif','_fd.tif')))\n",
    "    flow_accumulation.save(os.path.join(output_raster, file_name.replace('_ft.tif','_fa.tif')))\n",
    "    stream_definition.save(os.path.join(output_raster, file_name.replace('_ft.tif','_sd.tif')))\n",
    "    stream_link.save(os.path.join(output_raster, file_name.replace('_ft.tif','_sl.tif')))\n",
    "    stream_order.save(os.path.join(output_raster, file_name.replace('_ft.tif','_so.tif')))\n",
    "    catchment_grid.save(os.path.join(output_raster, file_name.replace('_ft.tif','_cg.tif')))\n",
    "    arcpy.CopyFeatures_management(catchment_polygon, os.path.join(output_vector, file_name.replace('_ft.tif','_cp.shp')))\n",
    "    arcpy.CopyFeatures_management(drainage_line, os.path.join(output_vector, file_name.replace('_ft.tif','_dl.shp')))\n",
    "    arcpy.CopyFeatures_management(drainage_point, os.path.join(output_vector, file_name.replace('_ft.tif','_dp.shp')))\n",
    "\n",
    "    # Clean up temporary in-memory data\n",
    "    arcpy.Delete_management(\"in_memory\")\n",
    "    print(f'processed {dem_file}')\n",
    "\n",
    "print(\"Hydrological analysis completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BISCAYNE_CANAL_ft.tif\n",
      "Point with Lowest Elevation (x, y): (-80.19337122203126, 25.90972254149375)\n",
      "Lowest Elevation Value: 0.041062500327825546\n",
      "LITTLE_RIVER_CANAL_ft.tif\n",
      "Point with Lowest Elevation (x, y): (-80.18937197316416, 25.85288505738805)\n",
      "Lowest Elevation Value: 0.0008676649886183441\n",
      "MIAMI_RIVER_ft.tif\n",
      "Point with Lowest Elevation (x, y): (-80.38556492230742, 25.81665342921218)\n",
      "Lowest Elevation Value: -9999.0\n",
      "SNAKE_CREEK_CANAL_ft.tif\n",
      "Point with Lowest Elevation (x, y): (-80.29971568390573, 25.956707854258184)\n",
      "Lowest Elevation Value: 0.4056850075721741\n",
      "BISCAYNE_CANAL_ft.tif\n",
      "Point with Lowest Elevation (x, y): (-80.19337122202796, 25.909722541487383)\n",
      "Lowest Elevation Value: 0.041062500327825546\n",
      "LITTLE_RIVER_CANAL_ft.tif\n",
      "Point with Lowest Elevation (x, y): (-80.18937197316416, 25.85288505738805)\n",
      "Lowest Elevation Value: 0.0008676649886183441\n",
      "NORTH_BISCAYNE_BAY_ft.tif\n",
      "Point with Lowest Elevation (x, y): (-80.15938358578103, 25.746257901143508)\n",
      "Lowest Elevation Value: -9999.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from arcpy.sa import *\n",
    "arcpy.env.addOutputsToMap = False\n",
    "# Enable overwriting of output files\n",
    "arcpy.env.overwriteOutput = True\n",
    "# Check out the Spatial Analyst extension\n",
    "arcpy.CheckOutExtension(\"Spatial\")\n",
    "# Define the directory where you want to start searching for .shp files\n",
    "start_directory = r'T:\\amandal2023$\\Working'\n",
    "ground_water=r'T:\\thindle2016$\\GW_Surfaces\\GW_Broward\\data\\wte_ft.tif'\n",
    "outras='Hydro'\n",
    "outvector='Drainage'\n",
    "# Use the glob library to search for .tif files in subdirectories named \"DEM\"\n",
    "dem_files = glob.glob(os.path.join(start_directory, '**/DEM/*.tif'), recursive=True)\n",
    "for dem_file in dem_files:\n",
    "    #print(dem_file)\n",
    "    a,b=os.path.split(dem_file)\n",
    "    print(b)\n",
    "    dp=(dem_file.replace('DEM',outvector)).replace('_ft.tif','_dp.shp')\n",
    "    dl=(dem_file.replace('DEM',outvector)).replace('_ft.tif','_dl.shp')\n",
    "    #print(dp, dl)\n",
    "    # Output feature class with elevation values\n",
    "    dp_ele = dp.replace('_dp.shp','_dph.shp')\n",
    "    # Extract elevation values to points\n",
    "    ExtractValuesToPoints(dp, ground_water, dp_ele)\n",
    "    # Initialize variables to store minimum elevation and corresponding point\n",
    "    min_elevation = None\n",
    "    min_point = None\n",
    "\n",
    "    # Open a search cursor to iterate through the points\n",
    "    with arcpy.da.SearchCursor(dp_ele, [\"RASTERVALU\", \"SHAPE@XY\"]) as cursor:\n",
    "        for row in cursor:\n",
    "            elevation = row[0]\n",
    "            point = row[1]\n",
    "\n",
    "            # Check if this elevation is lower than the current minimum\n",
    "            if min_elevation is None or elevation < min_elevation:\n",
    "                min_elevation = elevation\n",
    "                min_point = point\n",
    "\n",
    "    # Print the coordinates (x, y) of the point with the lowest elevation\n",
    "    print(f\"Point with Lowest Elevation (x, y): {min_point}\")\n",
    "    print(f\"Lowest Elevation Value: {min_elevation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from arcpy.sa import *\n",
    "arcpy.env.addOutputsToMap = False\n",
    "# Enable overwriting of output files\n",
    "arcpy.env.overwriteOutput = True\n",
    "# Check out the Spatial Analyst extension\n",
    "arcpy.CheckOutExtension(\"Spatial\")\n",
    "# Define the directory where you want to start searching for .shp files\n",
    "start_directory = r'T:\\amandal2023$\\Working'\n",
    "rainfall=r'Y:\\Datasets\\FL_NOAA14_Precipitation'\n",
    "folder='WTE'\n",
    "hucname=\"NAME\"\n",
    "# Use the glob library to search for .shp files in subdirectories\n",
    "shp_files = glob.glob(os.path.join(start_directory, '**/Huc12/StatePlane/*.shp'), recursive=True)\n",
    "ras_files = glob.glob(os.path.join(rainfall, '*.tif'), recursive=True)\n",
    "for ras in ras_files:\n",
    "    dirs, filename = os.path.split(ras)\n",
    "    fname=filename.replace('.tif','')\n",
    "    # Print the list of .shp files\n",
    "    for shp_file in shp_files:\n",
    "        print(fname)\n",
    "        # Split the file path into directory and file name\n",
    "        directory, file_name = os.path.split(shp_file)\n",
    "        output_folder=directory.replace('Huc12\\StatePlane',str(fname))\n",
    "        print(output_folder)\n",
    "        # Make sure the output folder exists, or create it if it doesn't\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "        # Create a cursor to iterate through the rows of the shapefile\n",
    "        with arcpy.da.SearchCursor(shp_file, [\"SHAPE@\", hucname]) as cursor:\n",
    "            for row in cursor:\n",
    "                # Define the output raster name based on the OID or any unique identifier\n",
    "                clipped = str(row[1].replace(' ','_'))+f'_{fname}.tif'\n",
    "                cliped_wte=os.path.join(output_folder, clipped)\n",
    "                print(cliped_wte)\n",
    "\n",
    "                # Clip the raster using the polygon geometry in the current row\n",
    "                arcpy.Clip_management(\n",
    "                    in_raster=ras,\n",
    "                    out_raster=cliped_wte,\n",
    "                    in_template_dataset=row[0],\n",
    "                    clipping_geometry=\"ClippingGeometry\"\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hialeah\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\DEMft\\BISCAYNE_CANAL_DEMft.tif\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\WTEft\\BISCAYNE_CANAL_WTEft.tif\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\DEMft\\LITTLE_RIVER_CANAL_DEMft.tif\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\WTEft\\LITTLE_RIVER_CANAL_WTEft.tif\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\DEMft\\MIAMI_RIVER_DEMft.tif\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\WTEft\\MIAMI_RIVER_WTEft.tif\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\DEMft\\SNAKE_CREEK_CANAL_DEMft.tif\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\WTEft\\SNAKE_CREEK_CANAL_WTEft.tif\n",
      "NorthMiami\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\DEMft\\BISCAYNE_CANAL_DEMft.tif\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\WTEft\\BISCAYNE_CANAL_WTEft.tif\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\DEMft\\LITTLE_RIVER_CANAL_DEMft.tif\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\WTEft\\LITTLE_RIVER_CANAL_WTEft.tif\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\DEMft\\NORTH_BISCAYNE_BAY_DEMft.tif\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\WTEft\\NORTH_BISCAYNE_BAY_WTEft.tif\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from arcpy.sa import *\n",
    "arcpy.env.addOutputsToMap = False\n",
    "# Check out the ArcGIS Spatial Analyst extension license\n",
    "arcpy.CheckOutExtension(\"Spatial\")\n",
    "# Enable overwriting of output files\n",
    "arcpy.env.overwriteOutput = True\n",
    "# Check out the Spatial Analyst extension\n",
    "arcpy.CheckOutExtension(\"Spatial\")\n",
    "# Define the directory where you want to start searching for .shp files\n",
    "start_directory = r'T:\\amandal2023$\\Working'\n",
    "\n",
    "def stat(ras):\n",
    "    minv = arcpy.GetRasterProperties_management(ras, \"MINIMUM\")\n",
    "    maxv = arcpy.GetRasterProperties_management(ras, \"MAXIMUM\")\n",
    "    meanv = arcpy.GetRasterProperties_management(ras, \"MEAN\")\n",
    "    return[minv,maxv,meanv]\n",
    "df=pd.DataFrame()\n",
    "    \n",
    "for folder in['Hialeah','NorthMiami']:\n",
    "    # Use the glob library to search for .tif files in subdirectories named \"DEM\"\n",
    "    dem_files = glob.glob(os.path.join(start_directory, f'{folder}\\HucWise\\DEMft\\*.tif'), recursive=True)\n",
    "    cascadeinputs=os.path.join(start_directory, f'{folder}\\Cascade.xlsx')\n",
    "    print(folder)\n",
    "    for dem_file in dem_files:\n",
    "        dirs, filename = os.path.split(dem_file)\n",
    "        HUC=(filename.replace('.tif','')).replace('_',' ')\n",
    "        # For example, setting all cells with a specific value (e.g., 0) to NoData\n",
    "        condition = Raster(dem_file) <0\n",
    "        # Use the SetNull function to set NoData for the specified condition\n",
    "        #output_ras = SetNull(condition, dem_file)\n",
    "        #dem=stat(output_ras)\n",
    "        print(dem_file)\n",
    "        WTEft=dem_file.replace('DEMft','WTEft')\n",
    "        WHC=dem_file.replace('DEMft','WHC')\n",
    "        ImperviousBinary=dem_file.replace('DEMft','ImperviousBinary')\n",
    "        WaterBinary=dem_file.replace('DEMft','WaterBinary')\n",
    "        print(WTEft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HUC</th>\n",
       "      <th>MaxElevation</th>\n",
       "      <th>MinElevation</th>\n",
       "      <th>se100yr24h_inch</th>\n",
       "      <th>se100yr3d_inch</th>\n",
       "      <th>se10yr1d_inch</th>\n",
       "      <th>se25y1d_inch</th>\n",
       "      <th>se25y3d_inch</th>\n",
       "      <th>se5y1d_inch</th>\n",
       "      <th>SCC0ft</th>\n",
       "      <th>SCC1ft</th>\n",
       "      <th>SCC2ft</th>\n",
       "      <th>SCC3ft</th>\n",
       "      <th>SCC4ft</th>\n",
       "      <th>SCC5ft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BISCAYNE CANAL DEMft</td>\n",
       "      <td>(22.917964935303)</td>\n",
       "      <td>(-0.59740918874741)</td>\n",
       "      <td>(14.788591793605)</td>\n",
       "      <td>(17.714295815448)</td>\n",
       "      <td>(8.4167448939109)</td>\n",
       "      <td>(10.697479617839)</td>\n",
       "      <td>(13.078479611144)</td>\n",
       "      <td>(6.9438469555913)</td>\n",
       "      <td>(0.07513358636072)</td>\n",
       "      <td>(0.024961169802939)</td>\n",
       "      <td>(0.010451176083262)</td>\n",
       "      <td>(5.5436661674997E-03)</td>\n",
       "      <td>(0.0035742051472)</td>\n",
       "      <td>(2.3572426985976E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LITTLE RIVER CANAL DEMft</td>\n",
       "      <td>(16.262218475342)</td>\n",
       "      <td>(-0.55647712945938)</td>\n",
       "      <td>(14.795024983088)</td>\n",
       "      <td>(17.73730823199)</td>\n",
       "      <td>(8.4550250371297)</td>\n",
       "      <td>(10.729308319092)</td>\n",
       "      <td>(13.153516658147)</td>\n",
       "      <td>(6.981566675504)</td>\n",
       "      <td>(0.015467885672054)</td>\n",
       "      <td>(3.9302118739224E-03)</td>\n",
       "      <td>(9.4120456331376E-04)</td>\n",
       "      <td>(3.6961413234163E-04)</td>\n",
       "      <td>(2.1682065855597E-04)</td>\n",
       "      <td>(1.371883325217E-04)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MIAMI RIVER DEMft</td>\n",
       "      <td>(51.221126556396)</td>\n",
       "      <td>(-3.8780920505524)</td>\n",
       "      <td>(14.457665322751)</td>\n",
       "      <td>(17.494975483174)</td>\n",
       "      <td>(8.2813673408664)</td>\n",
       "      <td>(10.486077542208)</td>\n",
       "      <td>(12.97295100543)</td>\n",
       "      <td>(6.8629918332003)</td>\n",
       "      <td>(0.14564273560804)</td>\n",
       "      <td>(0.12825067597749)</td>\n",
       "      <td>(0.11434607256987)</td>\n",
       "      <td>(0.1025016726493)</td>\n",
       "      <td>(0.092451918006369)</td>\n",
       "      <td>(0.08398134604812)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        HUC  ...                 SCC5ft\n",
       "0      BISCAYNE CANAL DEMft  ...  (2.3572426985976E-03)\n",
       "1  LITTLE RIVER CANAL DEMft  ...   (1.371883325217E-04)\n",
       "2         MIAMI RIVER DEMft  ...     (0.08398134604812)\n",
       "\n",
       "[3 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Z-score Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T:\\amandal2023$\\Working\\Hialeah\\Huc12\\StatePlane\\HIALEAH_HUC12s.shp\n",
      "1d100yr_5ft_pump\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\Inundation\\1d100yr_5ft_pump\n",
      "SNAKE_CREEK_CANAL_DEMft.tif\n",
      "SNAKE_CREEK_CANAL_1d100yr_5ft_pump.tif\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\Inundation\\1d100yr_5ft_pump\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\Inundation\\1d100yr_5ft_pump\\SNAKE_CREEK_CANAL_1d100yr_5ft_pump.tif\n",
      "6.3\n",
      "LITTLE_RIVER_CANAL_DEMft.tif\n",
      "LITTLE_RIVER_CANAL_1d100yr_5ft_pump.tif\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\Inundation\\1d100yr_5ft_pump\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\Inundation\\1d100yr_5ft_pump\\LITTLE_RIVER_CANAL_1d100yr_5ft_pump.tif\n",
      "5.74\n",
      "BISCAYNE_CANAL_DEMft.tif\n",
      "BISCAYNE_CANAL_1d100yr_5ft_pump.tif\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\Inundation\\1d100yr_5ft_pump\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\Inundation\\1d100yr_5ft_pump\\BISCAYNE_CANAL_1d100yr_5ft_pump.tif\n",
      "5.57\n",
      "MIAMI_RIVER_DEMft.tif\n",
      "MIAMI_RIVER_1d100yr_5ft_pump.tif\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\Inundation\\1d100yr_5ft_pump\n",
      "T:\\amandal2023$\\Working\\Hialeah\\HucWise\\Inundation\\1d100yr_5ft_pump\\MIAMI_RIVER_1d100yr_5ft_pump.tif\n",
      "5.8\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\Huc12\\StatePlane\\NORTH_MIAMI_HUC12s.shp\n",
      "1d100yr_5ft_pump\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\Inundation\\1d100yr_5ft_pump\n",
      "NORTH_BISCAYNE_BAY_DEMft.tif\n",
      "NORTH_BISCAYNE_BAY_1d100yr_5ft_pump.tif\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\Inundation\\1d100yr_5ft_pump\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\Inundation\\1d100yr_5ft_pump\\NORTH_BISCAYNE_BAY_1d100yr_5ft_pump.tif\n",
      "6.19\n",
      "LITTLE_RIVER_CANAL_DEMft.tif\n",
      "LITTLE_RIVER_CANAL_1d100yr_5ft_pump.tif\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\Inundation\\1d100yr_5ft_pump\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\Inundation\\1d100yr_5ft_pump\\LITTLE_RIVER_CANAL_1d100yr_5ft_pump.tif\n",
      "5.74\n",
      "BISCAYNE_CANAL_DEMft.tif\n",
      "BISCAYNE_CANAL_1d100yr_5ft_pump.tif\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\Inundation\\1d100yr_5ft_pump\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\HucWise\\Inundation\\1d100yr_5ft_pump\\BISCAYNE_CANAL_1d100yr_5ft_pump.tif\n",
      "5.57\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from arcpy.sa import *\n",
    "arcpy.env.addOutputsToMap = False\n",
    "# Enable overwriting of output files\n",
    "arcpy.env.overwriteOutput = True\n",
    "# Check out the Spatial Analyst extension\n",
    "arcpy.CheckOutExtension(\"Spatial\")\n",
    "# Define the directory where you want to start searching for .shp files\n",
    "start_directory = r'T:\\amandal2023$\\Working'\n",
    "hucname=\"NAME\"\n",
    "df=pd.read_excel(r'T:\\amandal2023$\\Working\\Cascade\\cascade_out_miss.xlsx')\n",
    "scenarios=df['Scenario'].unique()\n",
    "# Use the glob library to search for .shp files in subdirectories\n",
    "shp_files = glob.glob(os.path.join(start_directory, '**/StatePlane/*HUC12s.shp'), recursive=True)\n",
    "def outfolder(output_folder):\n",
    "    # Make sure the output folder exists, or create it if it doesn't\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "# Set the output coordinate system (EPSG 4269)\n",
    "output_coordinate_system = arcpy.SpatialReference(2881)\n",
    "# Print the list of .shp files\n",
    "for shp_file in shp_files:\n",
    "    print(shp_file)\n",
    "    # Split the file path into directory and file name\n",
    "    directory, file_name = os.path.split(shp_file)\n",
    "    #print(directory)\n",
    "    dem_folder=directory.replace('Huc12\\StatePlane','HucWise'+'\\\\'+'DEMft')\n",
    "    #print(dem_folder)\n",
    "    \n",
    "    for scenario in scenarios:\n",
    "        df1=df[df['Scenario']==scenario]\n",
    "        print(scenario)\n",
    "        output_folder=directory.replace('Huc12\\StatePlane','HucWise\\Inundation'+'\\\\'+str(scenario))\n",
    "        outfolder(output_folder)\n",
    "        print(output_folder)\n",
    "        mosaic_name=file_name.replace('.shp','_'+str(scenario)+'.tif')\n",
    "        #out_mosaic=os.path.join(output_folder, mosaic_name)\n",
    "        mlist=[]\n",
    "        # Create a cursor to iterate through the rows of the shapefile\n",
    "        with arcpy.da.SearchCursor(shp_file, [\"SHAPE@\", hucname]) as cursor:\n",
    "            for row in cursor:\n",
    "                dem_file=row[1].replace(' ','_')+'_DEMft.tif'\n",
    "                print(dem_file)\n",
    "                dem_path=os.path.join(dem_folder,dem_file)\n",
    "                df2=df1[df1['HUCs']==row[1]]\n",
    "                z_value=df2['Z_values'].values[0]\n",
    "                out_file=dem_file.replace('DEMft',scenario)\n",
    "                print(out_file)\n",
    "                print(output_folder)\n",
    "                outras=RasterCalculator([z_value,dem_path, 0.46],[\"x\", \"y\",\"z\"], \"float((x-y)/z)\")\n",
    "                output_raster=os.path.join(output_folder, out_file)\n",
    "\n",
    "                outras.save(output_raster)\n",
    "                mlist.append(output_raster)\n",
    "                print(output_raster)\n",
    "                print(z_value)\n",
    "        #arcpy.MosaicToNewRaster_management(filtered_files,out_mosaic, mosaic_ras,output_coordinate_system, \"8_BIT_UNSIGNED\", \"\", \"1\", \"LAST\",\"FIRST\")\n",
    "        arcpy.MosaicToNewRaster_management(mlist, output_folder, mosaic_name, output_coordinate_system, \"32_BIT_FLOAT\", \"\", \"1\", \"LAST\", \"FIRST\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1d5yr\n",
      "1d5yr_kt\n",
      "1d5yr_1ft\n",
      "1d5yr_1ft_kt\n",
      "1d5yr_2ft\n",
      "1d5yr_2ft_kt\n",
      "1d5yr_3ft\n",
      "1d5yr_3ft_kt\n",
      "1d5yr_4ft\n",
      "1d5yr_4ft_kt\n",
      "1d5yr_5ft\n",
      "1d5yr_5ft_kt\n",
      "1d10yr\n",
      "1d10yr_1ft\n",
      "1d10yr_1ft_kt\n",
      "1d10yr_2ft\n",
      "1d10yr_2ft_kt\n",
      "1d10yr_3ft\n",
      "1d10yr_3ft_kt\n",
      "1d10yr_4ft\n",
      "1d10yr_4ft_kt\n",
      "1d10yr_5ft\n",
      "1d10yr_5ft_kt\n",
      "1d10yr_kt\n",
      "1d100yr\n",
      "1d100yr_1ft\n",
      "1d100yr_1ft_kt\n",
      "1d100yr_2ft\n",
      "1d100yr_2ft_kt\n",
      "1d100yr_3ft\n",
      "1d100yr_3ft_kt\n",
      "1d100yr_4ft\n",
      "1d100yr_4ft_kt\n",
      "1d100yr_5ft\n",
      "1d100yr_5ft_kt\n",
      "1d100yr_kt\n",
      "3d25yr\n",
      "3d25yr_1ft\n",
      "3d25yr_1ft_kt\n",
      "3d25yr_2ft\n",
      "3d25yr_2ft_kt\n",
      "3d25yr_4ft_kt\n",
      "3d25yr_5ft\n",
      "3d25yr_5ft_kt\n",
      "3d25yr_kt\n",
      "kt\n"
     ]
    }
   ],
   "source": [
    "for scenario in scenarios:\n",
    "    print(scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(shp_file)\n",
    "        print(dirs)\n",
    "        # Split the file path into directory and file name\n",
    "        directory, file_name = os.path.split(shp_file)\n",
    "        print(directory)\n",
    "        output_folder=directory.replace('Huc12\\StatePlane','HucWise'+'\\\\'+dirs)\n",
    "        # Make sure the output folder exists, or create it if it doesn't\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "        # Create a cursor to iterate through the rows of the shapefile\n",
    "        with arcpy.da.SearchCursor(shp_file, [\"SHAPE@\", hucname]) as cursor:\n",
    "            for row in cursor:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Santa Rosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mosaicked 37 files to 100Y1D.tif\n",
      "Mosaicked 37 files to 100Y1D_S1.tif\n",
      "Mosaicked 37 files to 100Y1D_S2.tif\n",
      "Mosaicked 37 files to 100Y1D_S3.tif\n",
      "Mosaicked 37 files to 100Y1D_S4.tif\n",
      "Mosaicked 37 files to 100Y1D_S5.tif\n",
      "Mosaicked 37 files to 10Y1D.tif\n",
      "Mosaicked 37 files to 10Y1D_S1.tif\n",
      "Mosaicked 37 files to 10Y1D_S2.tif\n",
      "Mosaicked 37 files to 10Y1D_S3.tif\n",
      "Mosaicked 37 files to 10Y1D_S4.tif\n",
      "Mosaicked 37 files to 10Y1D_S5.tif\n",
      "Mosaicked 31 files to 25Y3D.tif\n",
      "Mosaicked 37 files to 25Y3D_S1.tif\n",
      "Mosaicked 37 files to 25Y3D_S2.tif\n",
      "Mosaicked 37 files to 25Y3D_S3.tif\n",
      "Mosaicked 37 files to 25Y3D_S4.tif\n",
      "Mosaicked 37 files to 25Y3D_S5.tif\n",
      "Mosaicked 37 files to 5Y1D.tif\n",
      "Mosaicked 37 files to 5Y1D_S1.tif\n",
      "Mosaicked 37 files to 5Y1D_S2.tif\n",
      "Mosaicked 37 files to 5Y1D_S3.tif\n",
      "Mosaicked 37 files to 5Y1D_S4.tif\n",
      "Mosaicked 37 files to 5Y1D_S5.tif\n"
     ]
    }
   ],
   "source": [
    "import arcpy\n",
    "import os\n",
    "arcpy.env.addOutputsToMap = False\n",
    "# Enable overwriting of output files\n",
    "arcpy.env.overwriteOutput = True\n",
    "# Set your workspace to the parent directory containing subdirectories with raster files\n",
    "workspace = r'T:\\amandal2023$\\Working\\Santa Rosa\\Datasets\\ZScore\\Hucwise'\n",
    "arcpy.env.workspace = workspace\n",
    "\n",
    "# Set the output directory for the mosaic\n",
    "output_mosaic_folder = r'T:\\amandal2023$\\Working\\Santa Rosa\\Datasets\\ZScore\\Mosaic'\n",
    "subdirectories =arcpy.ListWorkspaces()\n",
    "for subdirectory in subdirectories:\n",
    "    arcpy.env.workspace = subdirectory  # Set the current subdirectory as the workspace\n",
    "    raster_files = arcpy.ListRasters()  # List all raster files in the current subdirectory\n",
    "    if raster_files:\n",
    "        # Create a unique name for the mosaic dataset\n",
    "        mosaic_name = os.path.basename(subdirectory) + '.tif'\n",
    "        mosaic_dataset = os.path.join(output_mosaic_folder, mosaic_name)\n",
    "\n",
    "        # Mosaic the raster files\n",
    "        arcpy.MosaicToNewRaster_management(raster_files, output_mosaic_folder, mosaic_name,\"\", \"32_BIT_FLOAT\", \"\", \"1\", \"LAST\", \"FIRST\")\n",
    "\n",
    "        print(f\"Mosaicked {len(raster_files)} files to {mosaic_name}\")\n",
    "arcpy.env.workspace = workspace  # Set the workspace back to the parent directory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1 Hialeah_Northmaimi\n",
      "T2       \n",
      "T3 WMP_II\n",
      "T4 1\n",
      "JO 10 10.0000\n",
      "DT 0.200000\n",
      "TIME WINDOW \n",
      "  01JAN2000 0000 10JAN2000 0400\n",
      "BASIN Snake Creek Canal\n",
      "  RUNOFF GCUH 49.4207 0.0243000 0.000000 8.97400\n",
      "  DESIGN RAINFALL  5 1 6.46445\n",
      "VCAS RAIN_MEAS_PERIOD 1\n",
      "  INITIAL 2.10100\n",
      "  VCAS BASIN_STOR\n",
      "    VCAS SUBAREA LAND_AREA 31639.3 1.10100 21.4300\n",
      "    VCAS STAGE 2.10100 5.00000 10.0000 15.0000 21.4300\n",
      "  S-V 5\n",
      "    2.10100 778.181\n",
      "    5.00000 11830.1\n",
      "    10.0000 61625.9\n",
      "    15.0000 150331.\n",
      "    21.4300 321598.\n",
      "END\n",
      "BASIN Biscayne Canal\n",
      "  RUNOFF GCUH 28.2899 0.0200000 0.000000 11.3000\n",
      "  DESIGN RAINFALL  5 1 6.94385\n",
      "VCAS RAIN_MEAS_PERIOD 1\n",
      "  INITIAL 1.56500\n",
      "  VCAS BASIN_STOR\n",
      "    VCAS SUBAREA LAND_AREA 18111.3 0.565000 22.9100\n",
      "    VCAS STAGE 1.56500 5.00000 10.0000 15.0000 22.9100\n",
      "  S-V 5\n",
      "    1.56500 405.265\n",
      "    5.00000 7971.25\n",
      "    10.0000 36076.4\n",
      "    15.0000 84444.8\n",
      "    22.9100 202348.\n",
      "END\n",
      "BASIN Little River Canal\n",
      "  RUNOFF GCUH 31.9662 0.000180000 0.000000 9.25000\n",
      "  DESIGN RAINFALL  5 1 6.98157\n",
      "VCAS RAIN_MEAS_PERIOD 1\n",
      "  INITIAL 1.73100\n",
      "  VCAS BASIN_STOR\n",
      "    VCAS SUBAREA LAND_AREA 20464.8 0.731000 16.2600\n",
      "    VCAS STAGE 1.73100 5.00000 10.0000 16.2600\n",
      "  S-V 4\n",
      "    1.73100 658.922\n",
      "    5.00000 12008.4\n",
      "    10.0000 56610.9\n",
      "    16.2600 158899.\n",
      "END\n",
      "BASIN Miami River\n",
      "  RUNOFF GCUH 67.5557 0.100000 0.000000 14.7180\n",
      "  DESIGN RAINFALL  5 1 6.86299\n",
      "VCAS RAIN_MEAS_PERIOD 1\n",
      "  INITIAL 1.80000\n",
      "  VCAS BASIN_STOR\n",
      "    VCAS SUBAREA LAND_AREA 43249.4 0.800000 51.2200\n",
      "    VCAS STAGE 1.80000 5.00000 10.0000 20.0000 30.0000\n",
      "    VCAS STAGE 40.0000 51.2200\n",
      "  S-V 7\n",
      "    1.80000 428.891\n",
      "    5.00000 7565.64\n",
      "    10.0000 36301.4\n",
      "    20.0000 158106.\n",
      "    30.0000 365690.\n",
      "    40.0000 659052.\n",
      "    51.2200 1.09032e+006\n",
      "END\n",
      "BASIN North Biscayne Bay\n",
      "  RUNOFF GCUH 63.8127 0.00310000 0.000000 1.58400\n",
      "  DESIGN RAINFALL  5 1 6.98300\n",
      "VCAS RAIN_MEAS_PERIOD 1\n",
      "  INITIAL 1.80000\n",
      "  VCAS BASIN_STOR\n",
      "    VCAS SUBAREA LAND_AREA 40853.2 0.800000 16.8900\n",
      "    VCAS STAGE 1.80000 5.00000 10.0000 16.8900\n",
      "  S-V 4\n",
      "    1.80000 1269.52\n",
      "    5.00000 22394.4\n",
      "    10.0000 107452.\n",
      "    16.8900 328664.\n",
      "END\n",
      "STRUC FROM 2 TO 6\n",
      "  GATE -13.5000 2.30000 54.0000 2\n",
      "    OPENING 2\n",
      "      0.000000 1.00000\n",
      "      220.000 1.00000\n",
      "END\n",
      "STRUC FROM 3 TO 6\n",
      "  GATE -11.0000 3.20000 54.0000 2\n",
      "    OPENING 2\n",
      "      0.000000 1.00000\n",
      "      220.000 1.00000\n",
      "END\n",
      "STRUC FROM 4 TO 6\n",
      "  GATE -10.1000 4.40000 44.0000 2\n",
      "    OPENING 2\n",
      "      0.000000 1.00000\n",
      "      220.000 1.00000\n",
      "END\n",
      "STRUC FROM 4 TO 6\n",
      "  PUMP 5.00000 1.00000 1.45421e+006\n",
      "END\n",
      "OFFSITE 2\n",
      "  0.000000  1.80000\n",
      "  220.000  1.80000\n",
      "EJ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dat_file = r\"T:\\amandal2023$\\Temp\\cascade\\1d5yr_1ft.dat\"   \n",
    "\n",
    "with open(dat_file, 'r') as file:\n",
    "    text = file.read()\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cannot open 'post.shp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "In  \u001b[0;34m[8]\u001b[0m:\nLine \u001b[0;34m6\u001b[0m:     \u001b[34mwith\u001b[39;49;00m arcpy.da.SearchCursor(polygon_shapefile, fields) \u001b[34mas\u001b[39;49;00m cursor:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cannot open 'post.shp'\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "import arcpy\n",
    "arcpy.env.workspace = r\"T:\\Temp\\post1\"\n",
    "polygon_shapefile = \"post.shp\"\n",
    "fields = ['SHAPE@', 'gridcode']\n",
    "\n",
    "with arcpy.da.SearchCursor(polygon_shapefile, fields) as cursor:\n",
    "    for row in cursor:\n",
    "        if row[1] == 5:\n",
    "            # If the gridcode is 5, we need to search for nearby polygons.\n",
    "            current_polygon = row[0]\n",
    "            nearby_polygons = []\n",
    "\n",
    "            # Create a second cursor to search for nearby polygons within a 100-meter radius.\n",
    "            with arcpy.da.SearchCursor(polygon_shapefile, fields) as nearby_cursor:\n",
    "                for nearby_row in nearby_cursor:\n",
    "                    if nearby_row[1] != 5 and current_polygon.overlaps(nearby_row[0]):\n",
    "                        nearby_polygons.append(nearby_row)\n",
    "\n",
    "            if nearby_polygons:\n",
    "                # Sort nearby polygons by distance.\n",
    "                nearby_polygons.sort(key=lambda x: current_polygon.distanceTo(x[0]))\n",
    "\n",
    "                # Merge the current polygon with the nearest polygon that doesn't have gridcode 5.\n",
    "                nearest_polygon = nearby_polygons[0][0]\n",
    "                merged_polygon = current_polygon.union(nearest_polygon)\n",
    "\n",
    "                # Update the current polygon's geometry with the merged geometry.\n",
    "                with arcpy.da.UpdateCursor(polygon_shapefile, fields) as update_cursor:\n",
    "                    for update_row in update_cursor:\n",
    "                        if update_row[0] == current_polygon:\n",
    "                            update_row[0] = merged_polygon\n",
    "                            update_cursor.updateRow(update_row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ExecuteError",
     "evalue": "Failed to execute. Parameters are not valid.\nERROR 000732: Input Features: Dataset T:\\Temp\\post1\\post.shp does not exist or is not supported\nFailed to execute (MakeFeatureLayer).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mExecuteError\u001b[0m                              Traceback (most recent call last)",
      "In  \u001b[0;34m[7]\u001b[0m:\nLine \u001b[0;34m9\u001b[0m:     arcpy.MakeFeatureLayer_management(polygon_shapefile, \u001b[33m\"\u001b[39;49;00m\u001b[33mpolygon_layer\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\management.py\u001b[0m, in \u001b[0;32mMakeFeatureLayer\u001b[0m:\nLine \u001b[0;34m10316\u001b[0m: \u001b[34mraise\u001b[39;49;00m e\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\management.py\u001b[0m, in \u001b[0;32mMakeFeatureLayer\u001b[0m:\nLine \u001b[0;34m10313\u001b[0m: retval = convertArcObjectToPythonObject(gp.MakeFeatureLayer_management(*gp_fixargs((in_features, out_layer, where_clause, workspace, field_info), \u001b[34mTrue\u001b[39;49;00m)))\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\geoprocessing\\_base.py\u001b[0m, in \u001b[0;32m<lambda>\u001b[0m:\nLine \u001b[0;34m512\u001b[0m:   \u001b[34mreturn\u001b[39;49;00m \u001b[34mlambda\u001b[39;49;00m *args: val(*gp_fixargs(args, \u001b[34mTrue\u001b[39;49;00m))\n",
      "\u001b[0;31mExecuteError\u001b[0m: Failed to execute. Parameters are not valid.\nERROR 000732: Input Features: Dataset T:\\Temp\\post1\\post.shp does not exist or is not supported\nFailed to execute (MakeFeatureLayer).\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "import arcpy\n",
    "\n",
    "# Set the workspace and input shapefile\n",
    "arcpy.env.workspace = r\"T:\\Temp\\post1\"\n",
    "polygon_shapefile =r\"T:\\Temp\\post1\\post.shp\"\n",
    "fields = ['SHAPE@', 'gridcode']\n",
    "\n",
    "# Create a feature layer to make selections\n",
    "arcpy.MakeFeatureLayer_management(polygon_shapefile, \"polygon_layer\")\n",
    "\n",
    "# Iterate through the rows and select polygons with gridcode 5\n",
    "with arcpy.da.SearchCursor(polygon_shapefile, fields) as cursor:\n",
    "    for row in cursor:\n",
    "        if row[1] == 5:\n",
    "            current_polygon = row[0]\n",
    "\n",
    "            # Select the current polygon\n",
    "            arcpy.SelectLayerByLocation_management(\"polygon_layer\", \"INTERSECT\", current_polygon)\n",
    "\n",
    "            # Use Generate Near Table to find nearby polygons without gridcode 5\n",
    "            arcpy.GenerateNearTable_analysis(\"polygon_layer\", \"polygon_layer\", \"near_table\", search_radius=\"100 Meters\", location=\"NO_LOCATION\", angle=\"NO_ANGLE\", closest=\"ALL\")\n",
    "\n",
    "            # Iterate through the near table to find the nearest polygon without gridcode 5\n",
    "            with arcpy.da.SearchCursor(\"near_table\", [\"IN_FID\", \"NEAR_FID\"]) as near_cursor:\n",
    "                nearest_distance = float(\"inf\")\n",
    "                nearest_polygon = None\n",
    "                for near_row in near_cursor:\n",
    "                    if near_row[1] != row[1]:  # Check if it's not gridcode 5\n",
    "                        # Get the distance to the nearest polygon\n",
    "                        with arcpy.da.SearchCursor(polygon_shapefile, [\"SHAPE@\"], \"\\\"FID\\\" = \" + str(near_row[1])) as nearest_cursor:\n",
    "                            for nearest_row in nearest_cursor:\n",
    "                                distance = current_polygon.distanceTo(nearest_row[0])\n",
    "                                if distance < nearest_distance:\n",
    "                                    nearest_distance = distance\n",
    "                                    nearest_polygon = nearest_row[0]\n",
    "\n",
    "            # Merge the current polygon with the nearest polygon without gridcode 5\n",
    "            if nearest_polygon:\n",
    "                merged_polygon = current_polygon.union(nearest_polygon)\n",
    "\n",
    "                # Update the current polygon's geometry with the merged geometry\n",
    "                with arcpy.da.UpdateCursor(polygon_shapefile, fields) as update_cursor:\n",
    "                    for update_row in update_cursor:\n",
    "                        if update_row[0] == current_polygon:\n",
    "                            update_row[0] = merged_polygon\n",
    "                            update_cursor.updateRow(update_row)\n",
    "\n",
    "# Clean up temporary data\n",
    "arcpy.Delete_management(\"polygon_layer\")\n",
    "arcpy.Delete_management(\"near_table\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\\amandal2023$\\Working\\Homestead\\Huc12s\\boundary\n",
      "X:\\amandal2023$\\Working\\Homestead\\Huc12s\\dem_5ft\\MODEL_LAND_CANAL_dem_5ft.tif\n",
      "X:\\amandal2023$\\Working\\Homestead\\Huc12s\\dem_5ft\\MOWERY_CANAL_dem_5ft.tif\n",
      "X:\\amandal2023$\\Working\\Homestead\\Huc12s\\dem_5ft\\CANAL_S177_dem_5ft.tif\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from arcpy.sa import *\n",
    "arcpy.env.addOutputsToMap = False\n",
    "# Enable overwriting of output files\n",
    "arcpy.env.overwriteOutput = True\n",
    "# Check out the Spatial Analyst extension\n",
    "arcpy.CheckOutExtension(\"Spatial\")\n",
    "\n",
    "DEM_5ft=r'X:\\amandal2023$\\Working\\Homestead\\Huc12s\\boundary\\dem_5ft.tif'\n",
    "# Define the directory where you want to start searching for .shp files\n",
    "start_directory = r'X:\\amandal2023$\\Working\\Homestead\\Huc12s\\boundary'\n",
    "hucname=\"NAME\"\n",
    "# Use the glob library to search for .shp files in subdirectories\n",
    "shp_files = glob.glob(os.path.join(start_directory, '*.shp'), recursive=True)\n",
    "\n",
    "\n",
    "    \n",
    "# Print the list of .shp files\n",
    "for shp_file in shp_files:\n",
    "    #print(shp_file)\n",
    "    #print(dirs)\n",
    "    # Split the file path into directory and file name\n",
    "    directory, file_name = os.path.split(shp_file)\n",
    "    print(directory)\n",
    "    output_folder=r'X:\\amandal2023$\\Working\\Homestead\\Huc12s\\dem_5ft'\n",
    "    # Make sure the output folder exists, or create it if it doesn't\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    # Create a cursor to iterate through the rows of the shapefile\n",
    "    with arcpy.da.SearchCursor(shp_file, [\"SHAPE@\", hucname]) as cursor:\n",
    "        for row in cursor:\n",
    "            # Define the output raster name based on the OID or any unique identifier\n",
    "            clipped = str(row[1].replace(' ','_'))+f'_dem_5ft.tif'\n",
    "            cliped_wte=os.path.join(output_folder, clipped)\n",
    "            print(cliped_wte)\n",
    "\n",
    "            # Clip the raster using the polygon geometry in the current row\n",
    "            arcpy.Clip_management(\n",
    "                in_raster=DEM_5ft,\n",
    "                out_raster=cliped_wte,\n",
    "                in_template_dataset=row[0],\n",
    "                clipping_geometry=\"ClippingGeometry\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\\amandal2023$\\Working\\Homestead\\Huc12s\\boundary\\Huc12s_boundary.shp\n",
      "3d25yr\n",
      "X:\\amandal2023$\\Working\\Homestead\\Huc12s\\Inundation\\3d25yr\n",
      "MODEL_LAND_CANAL_dem_5ft.tif\n",
      "MODEL LAND CANAL\n",
      "1.92\n",
      "MODEL_LAND_CANAL_3d25yr.tif\n",
      "X:\\amandal2023$\\Working\\Homestead\\Huc12s\\Inundation\\3d25yr\n",
      "X:\\amandal2023$\\Working\\Homestead\\Huc12s\\Inundation\\3d25yr\\MODEL_LAND_CANAL_3d25yr.tif\n",
      "1.92\n",
      "MOWERY_CANAL_dem_5ft.tif\n",
      "MOWERY CANAL\n",
      "4.33\n",
      "MOWERY_CANAL_3d25yr.tif\n",
      "X:\\amandal2023$\\Working\\Homestead\\Huc12s\\Inundation\\3d25yr\n",
      "X:\\amandal2023$\\Working\\Homestead\\Huc12s\\Inundation\\3d25yr\\MOWERY_CANAL_3d25yr.tif\n",
      "4.33\n",
      "CANAL_S177_dem_5ft.tif\n",
      "CANAL S177\n",
      "5.79\n",
      "CANAL_S177_3d25yr.tif\n",
      "X:\\amandal2023$\\Working\\Homestead\\Huc12s\\Inundation\\3d25yr\n",
      "X:\\amandal2023$\\Working\\Homestead\\Huc12s\\Inundation\\3d25yr\\CANAL_S177_3d25yr.tif\n",
      "5.79\n",
      "3d25yr_struct\n",
      "X:\\amandal2023$\\Working\\Homestead\\Huc12s\\Inundation\\3d25yr_struct\n",
      "MODEL_LAND_CANAL_dem_5ft.tif\n",
      "MODEL LAND CANAL\n",
      "3.84\n",
      "MODEL_LAND_CANAL_3d25yr_struct.tif\n",
      "X:\\amandal2023$\\Working\\Homestead\\Huc12s\\Inundation\\3d25yr_struct\n",
      "X:\\amandal2023$\\Working\\Homestead\\Huc12s\\Inundation\\3d25yr_struct\\MODEL_LAND_CANAL_3d25yr_struct.tif\n",
      "3.84\n",
      "MOWERY_CANAL_dem_5ft.tif\n",
      "MOWERY CANAL\n",
      "3.76\n",
      "MOWERY_CANAL_3d25yr_struct.tif\n",
      "X:\\amandal2023$\\Working\\Homestead\\Huc12s\\Inundation\\3d25yr_struct\n",
      "X:\\amandal2023$\\Working\\Homestead\\Huc12s\\Inundation\\3d25yr_struct\\MOWERY_CANAL_3d25yr_struct.tif\n",
      "3.76\n",
      "CANAL_S177_dem_5ft.tif\n",
      "CANAL S177\n",
      "4.49\n",
      "CANAL_S177_3d25yr_struct.tif\n",
      "X:\\amandal2023$\\Working\\Homestead\\Huc12s\\Inundation\\3d25yr_struct\n",
      "X:\\amandal2023$\\Working\\Homestead\\Huc12s\\Inundation\\3d25yr_struct\\CANAL_S177_3d25yr_struct.tif\n",
      "4.49\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from arcpy.sa import *\n",
    "arcpy.env.addOutputsToMap = False\n",
    "# Enable overwriting of output files\n",
    "arcpy.env.overwriteOutput = True\n",
    "# Check out the Spatial Analyst extension\n",
    "arcpy.CheckOutExtension(\"Spatial\")\n",
    "# Define the directory where you want to start searching for .shp files\n",
    "start_directory = r'X:\\amandal2023$\\Working\\Homestead\\Huc12s\\boundary'\n",
    "hucname=\"NAME\"\n",
    "df=pd.read_excel(r'X:\\amandal2023$\\Working\\Homestead\\Cascade\\cascade_out_miss.xlsx')\n",
    "scenarios=df['Scenario'].unique()\n",
    "# Use the glob library to search for .shp files in subdirectories\n",
    "shp_files = glob.glob(os.path.join(start_directory, '*.shp'), recursive=True)\n",
    "def outfolder(output_folder):\n",
    "    # Make sure the output folder exists, or create it if it doesn't\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "# Set the output coordinate system (EPSG 4269)\n",
    "output_coordinate_system = arcpy.SpatialReference(2881)\n",
    "# Print the list of .shp files\n",
    "for shp_file in shp_files:\n",
    "    print(shp_file)\n",
    "    # Split the file path into directory and file name\n",
    "    directory, file_name = os.path.split(shp_file)\n",
    "    #print(directory)\n",
    "    dem_folder=r'X:\\amandal2023$\\Working\\Homestead\\Huc12s\\dem_5ft'\n",
    "    #print(dem_folder)\n",
    "    \n",
    "    for scenario in scenarios:\n",
    "        df1=df[df['Scenario']==scenario]\n",
    "        print(scenario)\n",
    "        output_folder=dem_folder.replace('dem_5ft','Inundation'+'\\\\'+str(scenario))\n",
    "        outfolder(output_folder)\n",
    "        print(output_folder)\n",
    "        mosaic_name=file_name.replace('.shp','_'+str(scenario)+'.tif')\n",
    "        #out_mosaic=os.path.join(output_folder, mosaic_name)\n",
    "        mlist=[]\n",
    "        # Create a cursor to iterate through the rows of the shapefile\n",
    "        with arcpy.da.SearchCursor(shp_file, [\"SHAPE@\", hucname]) as cursor:\n",
    "            for row in cursor:\n",
    "                dem_file=row[1].replace(' ','_')+'_dem_5ft.tif'\n",
    "                print(dem_file)\n",
    "                dem_path=os.path.join(dem_folder,dem_file)\n",
    "                print(row[1])\n",
    "                df2=df1[df1['HUCs']==row[1]]\n",
    "                z_value=df2['Z_values'].values[0]\n",
    "                print(z_value)\n",
    "                out_file=dem_file.replace('dem_5ft',scenario)\n",
    "                print(out_file)\n",
    "                print(output_folder)\n",
    "                outras=RasterCalculator([z_value,dem_path, 0.46],[\"x\", \"y\",\"z\"], \"float((x-y)/z)\")\n",
    "                output_raster=os.path.join(output_folder, out_file)\n",
    "\n",
    "                outras.save(output_raster)\n",
    "                mlist.append(output_raster)\n",
    "                print(output_raster)\n",
    "                print(z_value)\n",
    "        #arcpy.MosaicToNewRaster_management(filtered_files,out_mosaic, mosaic_ras,output_coordinate_system, \"8_BIT_UNSIGNED\", \"\", \"1\", \"LAST\",\"FIRST\")\n",
    "        arcpy.MosaicToNewRaster_management(mlist, output_folder, mosaic_name, output_coordinate_system, \"32_BIT_FLOAT\", \"\", \"1\", \"LAST\", \"FIRST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
