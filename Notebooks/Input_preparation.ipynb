{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1.1: Subset Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The follwing scripts automates the clipping and manage folder structure based on the HUCs Boundary. You can modify the input list of the datasets,however we recommend to have all the datasets listed below to follow the FAU (2020). We also recomend to have the same variables name for the list of the datasets so that it can be used to rename the datasets to maintain the consistancy and smooth the processing else you might need to debug manually. \n",
    "\n",
    "To use the provided script for clipping and mosaicking raster datasets based on HUC boundaries, follow these guidelines:\n",
    "#Set Project Directory: Update the project_dir variable to point to the root directory of your project where the geodatabase and raster datasets are located.\n",
    "\n",
    "#Configure HUC Boundary Settings:\n",
    "\n",
    "gdb_name: Replace \"Homestead\" with the name of your geodatabase (without the .gdb extension).\n",
    "huc_fname: Specify the name of the feature class that contains your HUC boundaries.\n",
    "huc_col: Set this to the column name in your feature class that represents the HUC names.\n",
    "id_col: Set this to the column name in your feature class that represents the HUC IDs.\n",
    "Define Dataset Paths:\n",
    "\n",
    "#datasets: Update this dictionary with the correct paths to your raster datasets. Ensure each key is a descriptive name and each value is the full path to the corresponding raster file.\n",
    "Running the Script:\n",
    "\n",
    "Ensure that ArcGIS and its Python environment are properly set up and that you have the necessary permissions to read from and write to the specified directories.\n",
    "The script will check the number of rows in the HUC feature class. If there is more than one row, it will create subdirectories under HUC12s for each HUC and clip the raster datasets accordingly. If only one row is present, it will clip the datasets and save them in a basedir directory.\n",
    "After clipping, the script groups the clipped raster files by their names and extensions, creates mosaics for each group, and saves them in the mosaic directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clipped dem_ft successfully and saved to X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\HUC12s\\030902061607_ModelLandCanal\\dem_ft.tif\n",
      "Clipped wte_ft successfully and saved to X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\HUC12s\\030902061607_ModelLandCanal\\wte_ft.tif\n",
      "Clipped whc_ratio successfully and saved to X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\HUC12s\\030902061607_ModelLandCanal\\whc_ratio.tif\n",
      "Clipped impervious successfully and saved to X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\HUC12s\\030902061607_ModelLandCanal\\impervious.tif\n",
      "Clipped water successfully and saved to X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\HUC12s\\030902061607_ModelLandCanal\\water.tif\n",
      "Clipped rain_1d5yr_in successfully and saved to X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\HUC12s\\030902061607_ModelLandCanal\\rain_1d5yr_in.tif\n",
      "Clipped rain_1d10yr_in successfully and saved to X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\HUC12s\\030902061607_ModelLandCanal\\rain_1d10yr_in.tif\n",
      "Clipped rain_1d100yr_in successfully and saved to X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\HUC12s\\030902061607_ModelLandCanal\\rain_1d100yr_in.tif\n",
      "Clipped rain_3d25yr_in successfully and saved to X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\HUC12s\\030902061607_ModelLandCanal\\rain_3d25yr_in.tif\n",
      "Clipped dem_ft successfully and saved to X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\HUC12s\\030902061605_MoweryCanal\\dem_ft.tif\n",
      "Clipped wte_ft successfully and saved to X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\HUC12s\\030902061605_MoweryCanal\\wte_ft.tif\n",
      "Clipped whc_ratio successfully and saved to X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\HUC12s\\030902061605_MoweryCanal\\whc_ratio.tif\n",
      "Clipped impervious successfully and saved to X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\HUC12s\\030902061605_MoweryCanal\\impervious.tif\n",
      "Clipped water successfully and saved to X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\HUC12s\\030902061605_MoweryCanal\\water.tif\n",
      "Clipped rain_1d5yr_in successfully and saved to X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\HUC12s\\030902061605_MoweryCanal\\rain_1d5yr_in.tif\n",
      "Clipped rain_1d10yr_in successfully and saved to X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\HUC12s\\030902061605_MoweryCanal\\rain_1d10yr_in.tif\n",
      "Clipped rain_1d100yr_in successfully and saved to X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\HUC12s\\030902061605_MoweryCanal\\rain_1d100yr_in.tif\n",
      "Clipped rain_3d25yr_in successfully and saved to X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\HUC12s\\030902061605_MoweryCanal\\rain_3d25yr_in.tif\n",
      "Clipped dem_ft successfully and saved to X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\HUC12s\\030902061606_CanalS177\\dem_ft.tif\n",
      "Clipped wte_ft successfully and saved to X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\HUC12s\\030902061606_CanalS177\\wte_ft.tif\n",
      "Clipped whc_ratio successfully and saved to X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\HUC12s\\030902061606_CanalS177\\whc_ratio.tif\n",
      "Clipped impervious successfully and saved to X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\HUC12s\\030902061606_CanalS177\\impervious.tif\n",
      "Clipped water successfully and saved to X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\HUC12s\\030902061606_CanalS177\\water.tif\n",
      "Clipped rain_1d5yr_in successfully and saved to X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\HUC12s\\030902061606_CanalS177\\rain_1d5yr_in.tif\n",
      "Clipped rain_1d10yr_in successfully and saved to X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\HUC12s\\030902061606_CanalS177\\rain_1d10yr_in.tif\n",
      "Clipped rain_1d100yr_in successfully and saved to X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\HUC12s\\030902061606_CanalS177\\rain_1d100yr_in.tif\n",
      "Clipped rain_3d25yr_in successfully and saved to X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\HUC12s\\030902061606_CanalS177\\rain_3d25yr_in.tif\n",
      "Creating mosaic for dem_ft.tif\n",
      "Creating mosaic for wte_ft.tif\n",
      "Creating mosaic for whc_ratio.tif\n",
      "Creating mosaic for impervious.tif\n",
      "Creating mosaic for water.tif\n",
      "Creating mosaic for rain_1d5yr_in.tif\n",
      "Creating mosaic for rain_1d10yr_in.tif\n",
      "Creating mosaic for rain_1d100yr_in.tif\n",
      "Creating mosaic for rain_3d25yr_in.tif\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'CheckedOut'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from arcpy.sa import *\n",
    "arcpy.env.addOutputsToMap = False\n",
    "# Enable overwriting of output files\n",
    "arcpy.env.overwriteOutput = True\n",
    "# Check out the Spatial Analyst extension\n",
    "arcpy.CheckOutExtension(\"Spatial\")\n",
    "# Set the project directory\n",
    "project_dir = r'X:\\amandal2023$\\Working\\Homestead\\Homestead_City'\n",
    "\n",
    "# Settings for the HUC boundary\n",
    "gdb_name = \"Homestead\"\n",
    "huc_fname = \"HUC12s_Boundary\"  # Name of the feature class\n",
    "huc_col = \"NAME\"  # Column representing the name of the HUCs\n",
    "id_col = \"HUC12\"  # Column representing the ID of the HUCs\n",
    "\n",
    "# Replace the paths of the datasets (please check the data management guide for details)\n",
    "datasets = {\n",
    "    'dem_ft': r'X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\Homestead_City\\dem_ft_mosaic.tif',\n",
    "    'wte_ft': r'X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\Homestead_City\\wte_ft.tif',\n",
    "    'whc_ratio': r'X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\Homestead_City\\whc.tif',\n",
    "    'impervious': r'X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\Homestead_City\\impervious.tif',\n",
    "    'water': r'X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\Homestead_City\\water.tif',\n",
    "    'rain_1d5yr_in': r'X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\Homestead_City\\rain_5y1d_in.tif',\n",
    "    'rain_1d10yr_in': r'X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\Homestead_City\\rain_10y1d_in.tif',\n",
    "    'rain_1d100yr_in': r'X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\Homestead_City\\rain_25y3d_in.tif',\n",
    "    'rain_3d25yr_in': r'X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\Homestead_City\\rain_100y1d_in.tif'\n",
    "}\n",
    "\n",
    "# Enable overwriting of output files\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "# Check out the Spatial Analyst extension\n",
    "arcpy.CheckOutExtension(\"Spatial\")\n",
    "\n",
    "# Set workspace to the project's directory\n",
    "arcpy.env.workspace = project_dir\n",
    "\n",
    "# Path to the geodatabase\n",
    "gdb_path = os.path.join(project_dir, f\"{gdb_name}.gdb\")\n",
    "huc_path = os.path.join(gdb_path, huc_fname)\n",
    "\n",
    "# Function to create directories if they don't exist\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "# Function to clip and save rasters\n",
    "def clip_and_save(huc, output_dir):\n",
    "    saved_paths = []\n",
    "    for key, raster in datasets.items():\n",
    "        output_raster = os.path.join(output_dir, f\"{key}.tif\")\n",
    "        try:\n",
    "            # Perform the extraction\n",
    "            arcpy.sa.ExtractByMask(raster, huc).save(output_raster)\n",
    "            # Check if the raster was saved successfully\n",
    "            if os.path.exists(output_raster):\n",
    "                saved_paths.append(output_raster)\n",
    "                print(f\"Clipped {key} successfully and saved to {output_raster}\")\n",
    "            else:\n",
    "                print(f\"Failed to save {key} to {output_raster}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error clipping {key}: {e}\")\n",
    "    return saved_paths\n",
    "\n",
    "# Read the feature class and count the number of rows\n",
    "with arcpy.da.SearchCursor(huc_path, [\"SHAPE@\", huc_col, id_col]) as cursor:\n",
    "    rows = [row for row in cursor]\n",
    "\n",
    "# Check the number of rows in the feature class\n",
    "if len(rows) > 1:\n",
    "    huc12s_dir = os.path.join(project_dir, \"HUC12s\")\n",
    "    create_dir(huc12s_dir)\n",
    "    \n",
    "    all_saved_paths = []  # List to collect all saved paths\n",
    "\n",
    "    for row in rows:\n",
    "        # Extract HUC name and ID\n",
    "        hucname = str(row[1]).title()\n",
    "        hucid = str(row[2])\n",
    "        # Define the output subdirectory name based on the HUC ID and HUC name\n",
    "        subdir = hucid + '_' + hucname.replace(' ', '')\n",
    "        output_folder = os.path.join(huc12s_dir, subdir)\n",
    "        create_dir(output_folder)\n",
    "        # Clip and save the rasters\n",
    "        saved_paths = clip_and_save(row[0], output_folder)\n",
    "        all_saved_paths.extend(saved_paths)  # Collect all paths\n",
    "\n",
    "    # Define the mosaic output folder\n",
    "    mosaic_dir = os.path.join(project_dir, \"mosaic\")\n",
    "    create_dir(mosaic_dir)\n",
    "\n",
    "    # Group files based on filename and extension\n",
    "    file_groups = {}\n",
    "    for file_path in all_saved_paths:\n",
    "        file_name, file_ext = os.path.splitext(os.path.basename(file_path))\n",
    "        if (file_name, file_ext) not in file_groups:\n",
    "            file_groups[(file_name, file_ext)] = []\n",
    "        file_groups[(file_name, file_ext)].append(file_path)\n",
    "\n",
    "    # Mosaic each group separately\n",
    "    for group, files in file_groups.items():\n",
    "        mosaic_name = f\"{group[0]}{group[1]}\"\n",
    "        print(f'Creating mosaic for {mosaic_name}')\n",
    "        mosaic_path = os.path.join(mosaic_dir, mosaic_name)\n",
    "        arcpy.MosaicToNewRaster_management(files, mosaic_dir, mosaic_name, pixel_type=\"32_BIT_FLOAT\", number_of_bands=1)\n",
    "    \n",
    "else:\n",
    "    basedir = os.path.join(project_dir, \"basedir\")\n",
    "    create_dir(basedir)\n",
    "    # Clip and save the rasters for the single HUC\n",
    "    saved_paths = clip_and_save(rows[0][0], basedir)\n",
    "    print(f\"Saved paths: {saved_paths}\")\n",
    "\n",
    "# Clean up\n",
    "arcpy.CheckInExtension(\"Spatial\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1.2 Processing ArcHydro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second section involves processing ArcHydro tools to obtain the initial stage and time of concentration for the basins, generating intermediate files such as drainage lines, drainage points, and more. This step requires the input datasets, mainly DEM files, to be organized in a specified folder structure.\n",
    "\n",
    "1.Folder Structure and Input Preparation\n",
    "#Ensure Proper Folder Structure:\n",
    "The DEM files should be organized under the HUC12s directory in subdirectories named after their respective HUC IDs. The structure should look like this:\n",
    "\n",
    "\n",
    "Project_Directory/HUC12s/{HUC_ID}_{HUC_Name}/dem_ft.tif\n",
    "\n",
    "Set Up Project Directory:\n",
    "Define your project directory where the input DEM files are located and where the outputs will be stored it should be same project directory which has been used in first section.\n",
    "\n",
    "2.Create Geodatabase:\n",
    "Ensure the (ArcHydro.gdb) geodatabase exists within the project directory to store the outputs. If the geodatabase doesn't exist, it will be created by the script.\n",
    "\n",
    "3.Processing Steps\n",
    "#Locate DEM Files:\n",
    "The script uses the glob library to search for DEM files in the specified directory structure.\n",
    "\n",
    "#Process DEM Files:\n",
    "For each DEM file found, the script performs the following steps using ArcHydro tools:\n",
    "\n",
    "Calculate Flow Direction\n",
    "Calculate Flow Accumulation\n",
    "Define Streams using a specified threshold\n",
    "Perform Stream Segmentation\n",
    "Calculate Stream Order\n",
    "Create Catchment Grid\n",
    "Convert Catchment Grid to Catchment Polygon\n",
    "Generate Drainage Lines\n",
    "Generate Drainage Points\n",
    "Save Results:\n",
    "The output rasters and vector files are saved in the ArcHydro.gdb geodatabase within the project directory. Each output file is named based on the HUC ID extracted from the subdirectory names.\n",
    "\n",
    "Clean Up:\n",
    "The script ensures that temporary in-memory data is cleaned up after processing each DEM file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geodatabase already exists at X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\ArcHydro.gdb\n",
      "Error processing X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\HUC12s\\030902061605_MoweryCanal\\dem_ft.tif: Failed to execute. Parameters are not valid.\n",
      "ERROR 000354: The name contains invalid characters\n",
      "Failed to execute (CopyFeatures).\n",
      "\n",
      "Error processing X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\HUC12s\\030902061606_CanalS177\\dem_ft.tif: Failed to execute. Parameters are not valid.\n",
      "ERROR 000354: The name contains invalid characters\n",
      "Failed to execute (CopyFeatures).\n",
      "\n",
      "Error processing X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\HUC12s\\030902061607_ModelLandCanal\\dem_ft.tif: Failed to execute. Parameters are not valid.\n",
      "ERROR 000354: The name contains invalid characters\n",
      "Failed to execute (CopyFeatures).\n",
      "\n",
      "Hydrological analysis completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import arcpy\n",
    "from arcpy.sa import *\n",
    "\n",
    "arcpy.env.addOutputsToMap = False\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.CheckOutExtension(\"Spatial\")\n",
    "\n",
    "# Set the project directory\n",
    "project_dir = r'X:\\amandal2023$\\Working\\Homestead\\Homestead_City'\n",
    "\n",
    "# Path to the geodatabase\n",
    "gdb_path = os.path.join(project_dir, 'ArcHydro.gdb')\n",
    "\n",
    "# Create the geodatabase if it doesn't exist\n",
    "if not arcpy.Exists(gdb_path):\n",
    "    arcpy.CreateFileGDB_management(project_dir, 'ArcHydro.gdb')\n",
    "    print(f\"Geodatabase created at {gdb_path}\")\n",
    "else:\n",
    "    print(f\"Geodatabase already exists at {gdb_path}\")\n",
    "\n",
    "# Use the glob library to search for dem_ft.tif files in the specified pattern\n",
    "dem_files = glob.glob(os.path.join(project_dir, 'HUC12s/**/dem_ft.tif'), recursive=True)\n",
    "\n",
    "# Function to extract numeric part of HUC ID from directory name\n",
    "def extract_hucid(directory):\n",
    "    return ''.join(filter(str.isdigit, os.path.basename(directory)))\n",
    "\n",
    "# Print the list of .tif files\n",
    "for dem_file in dem_files:\n",
    "    # Split the file path into directory and file name\n",
    "    directory, file_name = os.path.split(dem_file)\n",
    "    hucid = extract_hucid(directory)\n",
    "\n",
    "    # Generate output names based on hucid\n",
    "    fd_name = f\"{hucid}_fd\"\n",
    "    fa_name = f\"{hucid}_fa\"\n",
    "    sd_name = f\"{hucid}_sd\"\n",
    "    sl_name = f\"{hucid}_sl\"\n",
    "    so_name = f\"{hucid}_so\"\n",
    "    cg_name = f\"{hucid}_cg\"\n",
    "    cp_name = f\"{hucid}_cp\"\n",
    "    dl_name = f\"{hucid}_dl\"\n",
    "    dp_name = f\"{hucid}_dp\"\n",
    "\n",
    "    try:\n",
    "        # Step 1: Calculate Flow Direction\n",
    "        flow_direction = FlowDirection(dem_file, \"NORMAL\")\n",
    "\n",
    "        # Step 2: Calculate Flow Accumulation\n",
    "        flow_accumulation = FlowAccumulation(flow_direction)\n",
    "\n",
    "        # Step 3: Define Streams (Optional)\n",
    "        # Adjust the threshold value as needed to define streams\n",
    "        stream_definition = Con(flow_accumulation > 200, 5)\n",
    "\n",
    "        # Step 4: Stream Segmentation\n",
    "        stream_link = StreamLink(flow_direction, stream_definition)\n",
    "        stream_order = StreamOrder(stream_link, flow_direction)\n",
    "\n",
    "        # Step 5: Create Catchment Grid\n",
    "        catchment_grid = Watershed(flow_direction, stream_link)\n",
    "\n",
    "        # Step 6: Create Catchment Polygon\n",
    "        catchment_polygon = arcpy.RasterToPolygon_conversion(catchment_grid, \"in_memory/catchment_polygons\", \"NO_SIMPLIFY\")\n",
    "\n",
    "        # Step 7: Create Drainage Line\n",
    "        drainage_line = StreamToFeature(stream_link, flow_direction, \"in_memory/drainage_lines\")\n",
    "\n",
    "        # Step 8: Create Drainage Point\n",
    "        drainage_point = arcpy.RasterToPoint_conversion(stream_link, \"in_memory/drainage_points\")\n",
    "\n",
    "        \"\"\"# Save the results to the geodatabase\n",
    "        #flow_direction.save(os.path.join(gdb_path, fd_name))\n",
    "        flow_accumulation.save(os.path.join(gdb_path, fa_name))\n",
    "        stream_definition.save(os.path.join(gdb_path, sd_name))\n",
    "        stream_link.save(os.path.join(gdb_path, sl_name))\n",
    "        stream_order.save(os.path.join(gdb_path, so_name))\n",
    "        catchment_grid.save(os.path.join(gdb_path, cg_name))\n",
    "        \"\"\"\n",
    "        arcpy.CopyFeatures_management(catchment_polygon, os.path.join(gdb_path, cp_name))\n",
    "        arcpy.CopyFeatures_management(drainage_line, os.path.join(gdb_path, dl_name))\n",
    "        arcpy.CopyFeatures_management(drainage_point, os.path.join(gdb_path, dp_name))\n",
    "\n",
    "        # Clean up temporary in-memory data\n",
    "        arcpy.Delete_management(\"in_memory\")\n",
    "        print(f'Processed {dem_file}')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {dem_file}: {e}\")\n",
    "\n",
    "print(\"Hydrological analysis completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1.3 Unsaturated zone and Soil Storage calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Project Directory:\n",
    "\n",
    "Ensure the project_dir variable is correctly set to your project directory path. For example:\n",
    "python\n",
    "Copy code\n",
    "project_dir = r'X:\\amandal2023$\\Working\\Homestead\\Homestead_City'\n",
    "Run the Script:\n",
    "\n",
    "The script processes each DEM file and its corresponding rasters (water table elevation, water holding capacity, impervious, and water) to calculate the unsaturated zone depth and soil storage capacity.\n",
    "The script automatically saves the output rasters in the appropriate subdirectories.\n",
    "Review and Adjust Variables if Necessary:\n",
    "\n",
    "The script derives input file paths based on the dem_ft.tif file paths. Ensure your files are named and organized as per the directory structure above.\n",
    "If your files have different names, you may need to adjust the replace statements accordingly:\n",
    "python\n",
    "Copy code\n",
    "WTEft = dem_file.replace('dem_ft', 'wte_ft')\n",
    "WHC = dem_file.replace('dem_ft', 'whc_ratio')\n",
    "ImperviousBinary = dem_file.replace('dem_ft', 'impervious')\n",
    "WaterBinary = dem_file.replace('dem_ft', 'water')\n",
    "Output Files:\n",
    "\n",
    "The output files for soil storage and unsaturated zone calculations are saved in the same directories as the input dem_ft.tif files, with the names soilStorage and unsaturated, respectively.\n",
    "Mosaic Output:\n",
    "\n",
    "The script collects all processed rasters and groups them based on filename and extension.\n",
    "It then mosaics each group of rasters and saves the results in the mosaic directory.\n",
    "Ensure the mosaic directory exists or is created by the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\HUC12s\\030902061605_MoweryCanal\\dem_ft.tif\n",
      "Processed X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\HUC12s\\030902061606_CanalS177\\dem_ft.tif\n",
      "Processed X:\\amandal2023$\\Working\\Homestead\\Homestead_City\\HUC12s\\030902061607_ModelLandCanal\\dem_ft.tif\n",
      "Creating mosaic for soilStorage.tif\n",
      "Creating mosaic for unsaturated.tif\n",
      "Processing completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import arcpy\n",
    "from arcpy.sa import *\n",
    "\n",
    "arcpy.env.addOutputsToMap = False\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.CheckOutExtension(\"Spatial\")\n",
    "\n",
    "# Set the project directory\n",
    "project_dir = r'X:\\amandal2023$\\Working\\Homestead\\Homestead_City'\n",
    "\n",
    "\n",
    "all_saved_paths = []  # List to collect all saved paths\n",
    "# Print the list of .tif files\n",
    "for dem_file in dem_files:\n",
    "    \n",
    "    \n",
    "    try:\n",
    "\n",
    "        # Replace directory names to get corresponding file paths\n",
    "        WTEft = dem_file.replace('dem_ft', 'wte_ft')\n",
    "        WHC = dem_file.replace('dem_ft', 'whc_ratio')\n",
    "        ImperviousBinary = dem_file.replace('DEMft', 'impervious')\n",
    "        WaterBinary = dem_file.replace('dem_ft', 'water')\n",
    "\n",
    "        # Define output file paths\n",
    "        soilstorage = dem_file.replace('dem_ft', 'soilStorage')\n",
    "        unsaturated = dem_file.replace('dem_ft', 'unsaturated')\n",
    "\n",
    "        # Calculate soil storage\n",
    "        soil_outras = RasterCalculator([dem_file, WTEft, WHC, ImperviousBinary, WaterBinary, 12],\n",
    "                                       [\"a\", \"b\", \"d\", \"e\", \"f\", \"g\"], \n",
    "                                       \"float((a-b)*d*e*f*g)\")\n",
    "        soil_outras.save(soilstorage)\n",
    "\n",
    "        # Apply conditional to soil storage\n",
    "        outdata = Con(soilstorage, soilstorage, 0, \"VALUE >0\")\n",
    "        outdata.save(soilstorage)\n",
    "\n",
    "        # Calculate unsaturated storage\n",
    "        un_outras = RasterCalculator([dem_file, WTEft], [\"a\", \"b\"], \"float(a-b)\")\n",
    "        un_outras.save(unsaturated)\n",
    "\n",
    "        # Apply conditional to unsaturated storage\n",
    "        outdata = Con(unsaturated, unsaturated, 0, \"VALUE >0\")\n",
    "        outdata.save(unsaturated)\n",
    "        print(f'Processed {dem_file}')\n",
    "        all_saved_paths.extend([soilstorage,unsaturated])  # Collect all paths\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {dem_file}: {e}\")\n",
    "# Define the mosaic output folder\n",
    "mosaic_dir = os.path.join(project_dir, \"mosaic\")\n",
    "#create_dir(mosaic_dir)\n",
    "\n",
    "# Group files based on filename and extension\n",
    "file_groups = {}\n",
    "for file_path in all_saved_paths:\n",
    "    file_name, file_ext = os.path.splitext(os.path.basename(file_path))\n",
    "    if (file_name, file_ext) not in file_groups:\n",
    "        file_groups[(file_name, file_ext)] = []\n",
    "    file_groups[(file_name, file_ext)].append(file_path)\n",
    "\n",
    "# Mosaic each group separately\n",
    "for group, files in file_groups.items():\n",
    "    mosaic_name = f\"{group[0]}{group[1]}\"\n",
    "    print(f'Creating mosaic for {mosaic_name}')\n",
    "    mosaic_path = os.path.join(mosaic_dir, mosaic_name)\n",
    "    arcpy.MosaicToNewRaster_management(files, mosaic_dir, mosaic_name, pixel_type=\"32_BIT_FLOAT\", number_of_bands=1)\n",
    "\n",
    "print(\"Processing completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1.4 Input table for Cascade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final section of the input preparation stage involves summarizing required input parameters into an Excel table for simulating hydrological models based on different design storms. The design rainfall column can vary depending on the design storm events listed in the parent folder or in the data list mentioned in the first section. Similarly, soil storage capacity (SSC) can have multiple columns if we model for various scenarios, as SSC values are influenced by factors like sea level rise and king tides. This section generates an Excel file containing the summarized information with the following headings:\n",
    "\n",
    "HUC: Hydrologic Unit Code\n",
    "MaxElevation: Maximum elevation of the DEM\n",
    "MinElevation: Minimum elevation of the DEM\n",
    "r1d5yr: Mean rainfall for 1-day, 5-year design storm\n",
    "r1d10yr: Mean rainfall for 1-day, 10-year design storm\n",
    "r1d100yr: Mean rainfall for 1-day, 100-year design storm\n",
    "r3d25yr: Mean rainfall for 3-day, 25-year design storm\n",
    "SCC0ft: Soil Storage Capacity at 0 feet\n",
    "SCC1ft: Soil Storage Capacity at 1 foot\n",
    "SCC2ft: Soil Storage Capacity at 2 feet\n",
    "SCC3ft: Soil Storage Capacity at 3 feet\n",
    "SCC4ft: Soil Storage Capacity at 4 feet\n",
    "SCC5ft: Soil Storage Capacity at 5 feet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing directory: Homestead_City\n",
      "Completed processing for directory: Homestead_City\n",
      "Processing completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from arcpy.sa import *\n",
    "arcpy.env.addOutputsToMap = False\n",
    "\n",
    "# Check out the ArcGIS Spatial Analyst extension license\n",
    "arcpy.CheckOutExtension(\"Spatial\")\n",
    "\n",
    "# Enable overwriting of output files\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "# Define the project directory\n",
    "project_dir = r'X:\\amandal2023$\\Working\\Homestead\\Homestead_City'\n",
    "gdb_path = os.path.join(project_dir, 'ArcHydro.gdb')\n",
    "\n",
    "def stat(ras):\n",
    "    minv = arcpy.GetRasterProperties_management(ras, \"MINIMUM\")\n",
    "    maxv = arcpy.GetRasterProperties_management(ras, \"MAXIMUM\")\n",
    "    meanv = arcpy.GetRasterProperties_management(ras, \"MEAN\")\n",
    "    return [float(minv.getOutput(0)), float(maxv.getOutput(0)), float(meanv.getOutput(0))]\n",
    "\n",
    "# Use the glob library to search for .tif files in subdirectories named \"dem_ft.tif\"\n",
    "dem_files = glob.glob(os.path.join(project_dir, 'HUC12s/**/dem_ft.tif'), recursive=True)\n",
    "\n",
    "# Define the output directory for the Cascade input file\n",
    "cascade_output_dir = os.path.join(project_dir, 'Cascade', 'Inputs', 'table')\n",
    "os.makedirs(cascade_output_dir, exist_ok=True)\n",
    "\n",
    "# Use the base directory name for the Cascade input file name\n",
    "base_dir_name = os.path.basename(project_dir)\n",
    "cascadeinputs = os.path.join(cascade_output_dir, f'{base_dir_name}_Cascade.xlsx')\n",
    "\n",
    "# Define the temp directory for scc outputs\n",
    "temp_scc_dir = os.path.join(project_dir, 'Temp', 'scc')\n",
    "os.makedirs(temp_scc_dir, exist_ok=True)\n",
    "\n",
    "df_list = []\n",
    "\n",
    "print(f'Processing directory: {base_dir_name}')\n",
    "for dem_file in dem_files:\n",
    "    dirs, filename = os.path.split(dem_file)\n",
    "    HUC = dirs.split(os.sep)[-1].split('_')[0]  # Extract HUC ID from directory name\n",
    "    \n",
    "    dem = stat(dem_file)\n",
    "    WTEft = dem_file.replace('dem_ft.tif', 'wte_ft.tif')\n",
    "    WHC = dem_file.replace('dem_ft.tif', 'whc_ratio.tif')\n",
    "    ImperviousBinary = dem_file.replace('dem_ft.tif', 'impervious.tif')\n",
    "    WaterBinary = dem_file.replace('dem_ft.tif', 'water.tif')\n",
    "    \n",
    "    r1d5yr = stat(dem_file.replace('dem_ft.tif', 'rain_1d5yr_in.tif'))[2]\n",
    "    r1d10yr = stat(dem_file.replace('dem_ft.tif', 'rain_1d10yr_in.tif'))[2]\n",
    "    r1d100yr = stat(dem_file.replace('dem_ft.tif', 'rain_1d100yr_in.tif'))[2]\n",
    "    r3d25yr = stat(dem_file.replace('dem_ft.tif', 'rain_3d25yr_in.tif'))[2]\n",
    "    \n",
    "    scclist = []\n",
    "    for i in range(0, 6):\n",
    "        output_raster = os.path.join(temp_scc_dir, f'{HUC}_{i}.tif')\n",
    "        outras = RasterCalculator([dem_file, WTEft, i, WHC, ImperviousBinary, WaterBinary, 12],\n",
    "                                  [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\"], \n",
    "                                  \"float((a-(b+c))*d*e*f*g)\")\n",
    "        outras.save(output_raster)\n",
    "        outdata = Con(output_raster, output_raster, 0, \"VALUE >0\")\n",
    "        outdata.save(output_raster)\n",
    "        scc = stat(output_raster)[2]\n",
    "        scclist.append(scc)\n",
    "    \n",
    "    # Append the row to the list of dictionaries\n",
    "    df_list.append({'HUC': HUC, 'MaxElevation': dem[1], 'MinElevation': dem[0], 'r1d5yr': r1d5yr,\n",
    "                    'r1d10yr': r1d10yr, 'r1d100yr': r1d100yr, 'r3d25yr': r3d25yr,\n",
    "                    'SCC0ft': scclist[0], 'SCC1ft': scclist[1],\n",
    "                    'SCC2ft': scclist[2], 'SCC3ft': scclist[3], 'SCC4ft': scclist[4], 'SCC5ft': scclist[5]})\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame and save to Excel\n",
    "df = pd.DataFrame(df_list)\n",
    "df.to_excel(cascadeinputs, index=False)\n",
    "print(f'Completed processing for directory: {base_dir_name}')\n",
    "\n",
    "print(\"Processing completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BISCAYNE_CANAL_ft.tif\n",
      "Point with Lowest Elevation (x, y): (-80.19337122203126, 25.90972254149375)\n",
      "Lowest Elevation Value: 0.041062500327825546\n",
      "LITTLE_RIVER_CANAL_ft.tif\n",
      "Point with Lowest Elevation (x, y): (-80.18937197316416, 25.85288505738805)\n",
      "Lowest Elevation Value: 0.0008676649886183441\n",
      "MIAMI_RIVER_ft.tif\n",
      "Point with Lowest Elevation (x, y): (-80.38556492230742, 25.81665342921218)\n",
      "Lowest Elevation Value: -9999.0\n",
      "SNAKE_CREEK_CANAL_ft.tif\n",
      "Point with Lowest Elevation (x, y): (-80.29971568390573, 25.956707854258184)\n",
      "Lowest Elevation Value: 0.4056850075721741\n",
      "BISCAYNE_CANAL_ft.tif\n",
      "Point with Lowest Elevation (x, y): (-80.19337122202796, 25.909722541487383)\n",
      "Lowest Elevation Value: 0.041062500327825546\n",
      "LITTLE_RIVER_CANAL_ft.tif\n",
      "Point with Lowest Elevation (x, y): (-80.18937197316416, 25.85288505738805)\n",
      "Lowest Elevation Value: 0.0008676649886183441\n",
      "NORTH_BISCAYNE_BAY_ft.tif\n",
      "Point with Lowest Elevation (x, y): (-80.15938358578103, 25.746257901143508)\n",
      "Lowest Elevation Value: -9999.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from arcpy.sa import *\n",
    "arcpy.env.addOutputsToMap = False\n",
    "# Enable overwriting of output files\n",
    "arcpy.env.overwriteOutput = True\n",
    "# Check out the Spatial Analyst extension\n",
    "arcpy.CheckOutExtension(\"Spatial\")\n",
    "# Define the directory where you want to start searching for .shp files\n",
    "start_directory = r'T:\\amandal2023$\\Working'\n",
    "ground_water=r'T:\\thindle2016$\\GW_Surfaces\\GW_Broward\\data\\wte_ft.tif'\n",
    "outras='Hydro'\n",
    "outvector='Drainage'\n",
    "# Use the glob library to search for .tif files in subdirectories named \"DEM\"\n",
    "dem_files = glob.glob(os.path.join(start_directory, '**/DEM/*.tif'), recursive=True)\n",
    "for dem_file in dem_files:\n",
    "    #print(dem_file)\n",
    "    a,b=os.path.split(dem_file)\n",
    "    print(b)\n",
    "    dp=(dem_file.replace('DEM',outvector)).replace('_ft.tif','_dp.shp')\n",
    "    dl=(dem_file.replace('DEM',outvector)).replace('_ft.tif','_dl.shp')\n",
    "    #print(dp, dl)\n",
    "    # Output feature class with elevation values\n",
    "    dp_ele = dp.replace('_dp.shp','_dph.shp')\n",
    "    # Extract elevation values to points\n",
    "    ExtractValuesToPoints(dp, ground_water, dp_ele)\n",
    "    # Initialize variables to store minimum elevation and corresponding point\n",
    "    min_elevation = None\n",
    "    min_point = None\n",
    "\n",
    "    # Open a search cursor to iterate through the points\n",
    "    with arcpy.da.SearchCursor(dp_ele, [\"RASTERVALU\", \"SHAPE@XY\"]) as cursor:\n",
    "        for row in cursor:\n",
    "            elevation = row[0]\n",
    "            point = row[1]\n",
    "\n",
    "            # Check if this elevation is lower than the current minimum\n",
    "            if min_elevation is None or elevation < min_elevation:\n",
    "                min_elevation = elevation\n",
    "                min_point = point\n",
    "\n",
    "    # Print the coordinates (x, y) of the point with the lowest elevation\n",
    "    print(f\"Point with Lowest Elevation (x, y): {min_point}\")\n",
    "    print(f\"Lowest Elevation Value: {min_elevation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clip vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T:\\amandal2023$\\Miami-Dade\\Data\\Drainage_Lines.shp\n",
      "T:\\amandal2023$\\Working\\Hialeah\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\Hialeah\\Vector\\SNAKE_CREEK_CANAL_Fl.shp\n",
      "T:\\amandal2023$\\Working\\Hialeah\\Vector\\LITTLE_RIVER_CANAL_Fl.shp\n",
      "T:\\amandal2023$\\Working\\Hialeah\\Vector\\BISCAYNE_CANAL_Fl.shp\n",
      "T:\\amandal2023$\\Working\\Hialeah\\Vector\\MIAMI_RIVER_Fl.shp\n",
      "T:\\amandal2023$\\Miami-Dade\\Data\\Drainage_Lines.shp\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\Vector\\NORTH_BISCAYNE_BAY_Fl.shp\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\Vector\\LITTLE_RIVER_CANAL_Fl.shp\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\Vector\\BISCAYNE_CANAL_Fl.shp\n",
      "T:\\amandal2023$\\Miami-Dade\\Data\\Miami_Stations.shp\n",
      "T:\\amandal2023$\\Working\\Hialeah\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\Hialeah\\Vector\\SNAKE_CREEK_CANAL_Sp.shp\n",
      "T:\\amandal2023$\\Working\\Hialeah\\Vector\\LITTLE_RIVER_CANAL_Sp.shp\n",
      "T:\\amandal2023$\\Working\\Hialeah\\Vector\\BISCAYNE_CANAL_Sp.shp\n",
      "T:\\amandal2023$\\Working\\Hialeah\\Vector\\MIAMI_RIVER_Sp.shp\n",
      "T:\\amandal2023$\\Miami-Dade\\Data\\Miami_Stations.shp\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\Huc12\\StatePlane\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\Vector\\NORTH_BISCAYNE_BAY_Sp.shp\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\Vector\\LITTLE_RIVER_CANAL_Sp.shp\n",
      "T:\\amandal2023$\\Working\\NorthMiami\\Vector\\BISCAYNE_CANAL_Sp.shp\n"
     ]
    }
   ],
   "source": [
    "dlist={FlowLine:'Fl',SurfaceStations:'Sp'}\n",
    "import os\n",
    "import glob\n",
    "from arcpy.sa import *\n",
    "arcpy.env.addOutputsToMap = False\n",
    "# Enable overwriting of output files\n",
    "arcpy.env.overwriteOutput = True\n",
    "# Check out the Spatial Analyst extension\n",
    "arcpy.CheckOutExtension(\"Spatial\")\n",
    "# Define the directory where you want to start searching for .shp files\n",
    "start_directory = r'T:\\amandal2023$\\Working'\n",
    "hucname=\"NAME\"\n",
    "# Use the glob library to search for .shp files in subdirectories\n",
    "shp_files = glob.glob(os.path.join(start_directory, '**/StatePlane/*.shp'), recursive=True)\n",
    "for dirs, data in dlist.items():\n",
    "    \n",
    "    # Print the list of .shp files\n",
    "    for shp_file in shp_files:\n",
    "        #print(shp_file)\n",
    "        print(dirs)\n",
    "        # Split the file path into directory and file name\n",
    "        directory, file_name = os.path.split(shp_file)\n",
    "        print(directory)\n",
    "        output_folder=directory.replace('Huc12\\StatePlane','Vector')\n",
    "        # Make sure the output folder exists, or create it if it doesn't\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "        # Create a cursor to iterate through the rows of the shapefile\n",
    "        with arcpy.da.SearchCursor(shp_file, [\"SHAPE@\", hucname]) as cursor:\n",
    "            for row in cursor:\n",
    "                # Define the output raster name based on the OID or any unique identifier\n",
    "                clipped = str(row[1].replace(' ','_'))+f'_{data}.shp'\n",
    "                cliped_wte=os.path.join(output_folder, clipped)\n",
    "                print(cliped_wte)\n",
    "                # Perform the clip operation\n",
    "                arcpy.analysis.Clip(dirs, row[0], cliped_wte)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
